<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-码农/deep_learning/CNN" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">CNN | Coisini</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://doc.minddiy.top/码农/deep_learning/CNN/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="CNN | Coisini"><meta data-rh="true" name="description" content="我们开始探讨 Network 的架构设计,第一个Network 架构的变形是 Convolutional 的 Neural Network,它的缩写是 CNN,它是专门被用在影像上的,我希望透过 CNN 这个例子,来让大家知道Network 的架构,它的设计有什麼样的想法,那為什麼设计 Network 的架构,可以让我们的 Network 结果做得更好。"><meta data-rh="true" property="og:description" content="我们开始探讨 Network 的架构设计,第一个Network 架构的变形是 Convolutional 的 Neural Network,它的缩写是 CNN,它是专门被用在影像上的,我希望透过 CNN 这个例子,来让大家知道Network 的架构,它的设计有什麼样的想法,那為什麼设计 Network 的架构,可以让我们的 Network 结果做得更好。"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://doc.minddiy.top/码农/deep_learning/CNN/"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/CNN/" hreflang="en"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/CNN/" hreflang="x-default"><meta name="google-site-verification" content="1FUPX6Qo4y3ecU623ShEurhgnjhSTjK49rRMhEDlzFA">
<link rel="stylesheet" href="/katex/katex.min.css">
<script src="/js/matomo.js" async defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.79037026.css">
<script src="/assets/js/runtime~main.468f2b27.js" defer="defer"></script>
<script src="/assets/js/main.4763ab3e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Coisini</b></a></div><div class="navbar__items navbar__items--right"><a href="https://minddiy.top" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Main site<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>CNN</h1></header>
<p>我们开始探讨 Network 的架构设计,第一个Network 架构的变形是 Convolutional 的 Neural Network,它的缩写是 CNN,它是专门被用在影像上的,我希望透过 CNN 这个例子,来让大家知道Network 的架构,它的设计有什麼样的想法,那為什麼设计 Network 的架构,可以让我们的 Network 结果做得更好。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="image-classification">Image Classification<a href="#image-classification" class="hash-link" aria-label="Direct link to Image Classification" title="Direct link to Image Classification">​</a></h2>
<p>接下来要讲的例子是跟影像有关的,我们要做影像的分类,也就是给机器一张图片,它要去决定说这张图片裡面有什麼样的东西,那怎麼做呢</p>
<p>我们已经跟大家讲过怎麼做分类这件事情,在以下的讨论裡面,我们都假设我们的模型<strong>输入的图片大小是固定的</strong>,举例来说 它固定输入的图片大小,都是 100 × 100 的解析度,就算是今天 Deep Learning 已经这麼的 Popular,我们往往都还是需要假设说,一个模型输入的影像大小都是一样的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329144404567-252c249a642f7361d4d8e505122842e9.png" width="591" height="395" class="img_ev3q"></p>
<p>图片可能有大有小,而且不是所有图片都是正方形的啊,有长方形的怎麼办</p>
<p>今天常见的处理方式,丢进影像辨识系统处理方式就是,<strong>把所有图片都先 Rescale 成大小一样</strong>,再丢到影像的辨识系统裡面,</p>
<p>我们的模型的输出应该是什麼呢,我们模型的目标是分类,所以我们会把每一个类别,表示成一个 One-Hot 的 Vector,我的目标就叫做 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span></span></span></span></p>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,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" width="115" height="250" class="img_ev3q"></p>
<p>在这个 One-Hot 的 Vector 裡面,假设我们现在<strong>类别是一个猫的话,那猫所对应的 Dimension,它的数值就是 1,其他的东西所对的 Dimension 的数值就是 0</strong></p>
<p>那<strong>这个 Dimension 的长度就决定了,你现在的模型可以辨识出多少不同种类的东西</strong>,如果你向量的长度是 2000,就代表说你这个模型,可以辨识出 2000 种不同的东西,那今天比较强的影像辨识系统,往往可以辨识出 1000 种以上的东西,甚至到上万种不同的 Object,那如果你今天希望你的影像辨识系统,它可以辨识上万种 Object,那你的 Label 就会是一个上万维,维度是上万的 One-Hot Vector</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329145326452-8bc78c3a7e00a88a7be8d9a6ea302607.png" width="746" height="463" class="img_ev3q"></p>
<p>我的模型的输出通过 Softmax 以后,输出是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9463em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>,然后我们希望 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9463em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 和<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span></span></span></span>的 Cross Entropy 越小越好,接下来的问题是怎麼<strong>把一张影像当做一个模型的输入</strong></p>
<p>其实对於一个 Machine 来说,<strong>一张图片其实是一个三维的 Tensor</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329150221441-06da89eb43e3ac024025e353173ea46b.png" width="571" height="378" class="img_ev3q"></p>
<p>如果不知道 Tensor 是什麼的话,你就想成它是<strong>维度大於 2 的矩阵就是 Tensor</strong>,矩阵是二维,那二维以上的 超过二维的矩阵,你就叫它 Tensor</p>
<p>一张图片它是一个三维的 Tensor,其中一维代表图片的<strong>宽</strong>,另外一维代表图片的<strong>高</strong>,还有一维代表图片的 <strong>Channel 的数目</strong></p>
<p>一张彩色的图片,今天它每一个 Pixel,都是由 R G B 三个顏色所组成的,所以这三个 Channel 就代表了 R G B 三个顏色,那长跟宽就代表了今天这张图片的解析度,代表这张图片裡面有的 Pixel,有的像  素的数目</p>
<p>那接下来我们就要<strong>把这一个三维的 Tensor拉直,就可以丢到一个 Network 裡面去了</strong></p>
<p>到目前為止我们所讲的 Network,它的输入其实都是一个向量,所以我们只要能够把一张图片变成一个向量,我们就可以把它当做是 Network 的输入,但是怎麼把这个三维的 Tensor 变成一个向量呢,那最直觉的方法就是直接拉直它</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329150453073-2954847345fff1666b22cad98808ce98.png" width="773" height="541" class="img_ev3q"></p>
<p>一个三维的 Tensor 裡面有几个数字呢</p>
<p>在这个例子裡面有 100 × 100×3 个数字,把这些数字通通拿出来排成一排,就是一个巨大的向量,这个向量可以作為 Network 的输入</p>
<p>而这个向量裡面,<strong>每一维它裡面存的数值,其实就是某一个 Pixel某一个顏色的强度</strong>,每一个 Pixel 有 R G B 三个顏色所组成</p>
<p>这个向量啊,我们可以把它当做是一个 Network 的输入,那我们到目前為止,只讲过了 Fully Connected Network,好 如果我们把向量当做 Network 的输入,我们 Input 这边 Feature Vector,它的长度就是 100 × 100×3</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329151609783-e22216897629137daefceba24205ed00.png" width="743" height="548" class="img_ev3q"></p>
<p>非常长的一个 Vector,那假设我们现在的,第一层的 Neuron 的数目有 1000 个,那你能计算一下这边第一层,总共有多少个 Weight 吗</p>
<p>我们每一个 Neuron,它跟输入的向量的每一个数值,都会有一个 Weight,所以如果输入的向量长度是 100 × 100×3,有 1000 个 Neuron,那我们现在第一层的 Weight,就有 1000×100 × 100×3,也就是 3×10 的 7 次方</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329151709793-333cf001da35ae0ca7838b43154d4bc1.png" width="725" height="562" class="img_ev3q"></p>
<p>是一个非常巨  大的数目,那如果参数越多会有什麼样的问题呢</p>
<p>虽然随著参数的增加,我们可以增加模型的弹性,我们可以增加它的能力,但是我们也<strong>增加了 Overfitting 的风险</strong>,有关什麼叫模型的弹性,到底 Overfitting 怎麼產生的,下週吴培元老师<a href="https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/W14_PAC-introduction.pdf%E4%BC%9A%E4%BB%8E%E6%95%B0%E5%AD%A6%E4%B8%8A,%E7%BB%99%E5%A4%A7%E5%AE%B6%E9%9D%9E%E5%B8%B8%E6%B8%85%E6%A5%9A%E7%9A%84%E8%AF%81%E6%98%8E,%E9%82%A3%E6%88%91%E4%BB%AC%E8%BF%99%E8%BE%B9%E5%B0%B1%E8%AE%B2%E6%A6%82%E5%BF%B5%E4%B8%8A,%E5%A6%82%E6%9E%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BC%B9%E6%80%A7%E8%B6%8A%E5%A4%A7,%E5%B0%B1%E8%B6%8A%E5%AE%B9%E6%98%93" target="_blank" rel="noopener noreferrer">https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/W14_PAC-introduction.pdf会从数学上,给大家非常清楚的证明,那我们这边就讲概念上,如果模型的弹性越大,就越容易</a> Overfitting</p>
<p>那我们怎麼减少在做影像辨识的时候,怎麼避免使用这麼多的参数呢</p>
<p>那考虑到影像辨识这个问题本身的特性,其实<strong>我们并不一定需要 Fully Connected</strong> 这件事,我们其实不需要每一个 Neuron,跟 Input的每一个 Dimension 都有一个 Weight</p>
<p>怎麼说呢,接下来就是对影像辨识这个问题,对影像本身的特性的一些观察</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="observation-1">Observation 1<a href="#observation-1" class="hash-link" aria-label="Direct link to Observation 1" title="Direct link to Observation 1">​</a></h2>
<p>第一个观察是,对影像辨识这个问题而言,假设我们想要知道这张图片裡面有一隻动物,这个动物是一个鸟 要怎麼做呢</p>
<p>也许对一个影像辨识的系统而言,对一个影像辨识的 Neuron,对一个影像辨识的类神经网路裡面的神经而言,它要做的就是侦测说现在这张图片裡面,有没有出现一些特别重要的 Pattern</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329152250346-30dcaefb6247d7ff1d803a60e16e20c8.png" width="834" height="472" class="img_ev3q"></p>
<p>举例来说 如果现在</p>
<ul>
<li>有某一个 Neuron ,它看到鸟嘴这个 Pattern</li>
<li>有某个 Neuron 又说,它看到眼睛这个 Pattern</li>
<li>又有某个 Neuron 说,它看到鸟爪这个 Pattern</li>
</ul>
<p>也许看到这些 Pattern 综合起来就代表说,我们看到了一隻鸟,类神经网路就可以告诉你说,因為看到了这些 Pattern,所以它看到了一隻鸟</p>
<p>那也许你会觉得说,看 Pattern 然后决定它是什麼,这件事情好像没有很聪明,但你仔细想想,<strong>人是不是也是用同样的方法,来看一张图片中有没有一隻鸟呢,</strong></p>
<p>举例来说这一个例子,不知道你有没有看到,这裡面有什麼样的动物?</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329152538714-3ce9e109b075759149d86acd06710759.png" width="457" height="467" class="img_ev3q"></p>
<p>你看这边<strong>有一个鸟嘴</strong>,这边有一个眼睛,看起来牠是一个乌鸦</p>
<p>但是牠其实是一隻猫</p>
<p>如果你看到牠是一隻鸟的话,那你就应该放下酒杯了,因為这是一隻猫</p>
<p>所以其实就算是人,我们在判断一个物件的时候,往往也是抓最重要的特徵,然后看到这些特徵以后,你很直觉的就会觉得说,你看到了某种物件,对机器来说,也许这也是一个有效的,判断影像中有什麼物件的方法</p>
<p>但是假设我们现在用 Neuron 做的事情,其实就是判断说现在有没有某种 Pattern 出现,那也许<strong>我们并不需要每一个 Neuron都去看一张完整的图片</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329153053000-cef3f890303265fc1612016b1a3e8e73.png" width="807" height="542" class="img_ev3q"></p>
<p>因為这一些重要的 Pattern,比如说鸟嘴 比如说眼睛 比如说鸟爪,并不需要 看整张完整的图片,才能够得到这些资讯,</p>
<p><strong>所以这些 Neuron 也许根本就不需要,把整张图片当作输入,它们只需要把图片的一小部分当作输入,就足以让它们侦测某些特别关键的 Pattern有没有出现了</strong></p>
<p>这是第一个观察,根据这个观察,我们就可以做第一个简化 怎麼简化呢</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="simplification-1">Simplification 1<a href="#simplification-1" class="hash-link" aria-label="Direct link to Simplification 1" title="Direct link to Simplification 1">​</a></h2>
<p>在 CNN 裡面有一个这样的做法,我们会设定一个区域叫做 ==Receptive Field==,<strong>每一个 Neuron 都只关心自己的 Receptive Field 裡面发生的事情就好了</strong></p>
<p>举例来说 你会先定义说这个<strong>蓝色的 Neuron</strong>,它的守备范围就是这一个 Receptive Field,那这个 Receptive Field 裡面有 3×3×3 个数值,那对蓝色的 Neuron 来说,它只需要关心这一个小范围就好了,不需要在意整张图片裡面有什麼东西</p>
<p>那这个 Neuron,怎麼考虑这个 Receptive Field 裡,有没有发生什麼样的事情呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329154413724-2335859836c9efbc87077c0f073dc1f3.png" width="780" height="474" class="img_ev3q"></p>
<p>它要做的事情就是</p>
<ul>
<li>把这 3×3×3 的数值<strong>拉直</strong>,变成一个长度是 3×3×3 也就是 27 维的向量,再把这 27 维的向量作為这个 Neuron 的输入</li>
<li>这个 Neuron 会给 27 维的向量的,**每一个 Dimension 一个 Weight,**所以这个 Neuron 有 3×3×3  27个 Weight,</li>
<li>再<strong>加上 Bias</strong> 得到的输出,这个输出再送给下一层的 Neuron 当作输入,</li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329154527924-2df4174332f550990079154680112b3d.png" width="800" height="557" class="img_ev3q"></p>
<p>所以每一个 Neuron,它只考虑自己的 Receptive Field,那这个 Receptive Field 要怎麼决定出来呢,那<strong>这个就要问你自己了</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329154750439-3804b54a7166a6a7e2d06de82cdbd403.png" width="790" height="435" class="img_ev3q"></p>
<ul>
<li>你可以说这边有个蓝色的 Neuron,它就看左上角这个范围,这是它的 Receptive Field</li>
<li>另外又有另外一个黄色的 Neuron,它是看右下角这个 3×3×3 的范围</li>
<li>那 Receptive Field 彼此之间也<strong>可以是重叠的</strong>,比如说我现在画一个 Receptive Field,那这个地方它是绿色的 Neuron 的守备范围,它跟蓝色的跟黄色的都有一些重叠的空间</li>
<li>那你甚至可以<strong>两个不同的 Neuron,它们守备看到的范围是一样的</strong>,也许一个范围使用一个 Neuron 来守备,你没有办法侦测所有的 Pattern,所以同个范围可以有多个不同的 Neuron,所以同个 Receptive Field,它们可以有多个</li>
</ul>
<p>那接下来你就会浮想联翩有各式各样的想法,举例来说,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329155519341-987cbf2f6edef27fb8378c03bb796dd2.png" width="803" height="605" class="img_ev3q"></p>
<ul>
<li>那我可不可以 <strong>Receptive Field 有大有小</strong>呢?因為毕竟 Pattern 有的比较小 有的比较大,有的 Pattern 也许在 3×3 的范围内,就可以被侦测出来,有的 Pattern 也许要 11×11 的范围,才能被侦测出来,可以,这个算是常见的招式了</li>
<li>我可不可以 Receptive Field,<strong>只考虑某些 Channel</strong> 呢,我们这边看起来我们的 Receptive Field,是 R G B 三个 Channel 都考虑,但也许有些 Pattern,只在红色的 Channel 会出现,也许有些 Pattern,只在蓝色的 Channel 会出现啊,我可不可以有的 Neuron 只考虑一个 Channel 呢？可以,其实之后在讲到 Network Compression的时候,会讲到这种 Network 的架构,在一般 CNN 裡面你不常这样子的考虑,但是有这样子的做法</li>
<li>那有人会问说这边的 Receptive Field,通通都是正方形的,你刚才举的例子裡面,3×3  11×11 也都是正方形的,可不可以是长方形？可以！<strong>可以是长方形的</strong>,这完全都是你自己设计的,Receptive Field 是你自己定义的,你完全可以根据你对这个问题的理解,决定你觉得 Receptive Field 应该要长什麼样子</li>
<li>你可能会说 Receptive Field <strong>一定要相连吗</strong>？我们可不可以说有一个 Neuron,它的 Receptive Field 就是影像的左上角,跟右上角。<strong>理论上可以</strong>,但是你就要想看為什麼你要这麼做嘛,会不会有什麼 Pattern 是会,也要看一个图片的左上角,跟右下角才能够找到的,也许没有 如果没有的话,这种 Receptive Field 就没什麼用,我们之所以 Receptive Field 都是,一个相连的领地,就是我们觉得要侦测一个 Pattern,那这个 Pattern,它就出现在整个图片裡面的某一个位置,而不是出现,而不是分成好几部分,出现在图片裡面的不同的位置,所以 Receptive Field 呢 它都是相,通常见到的都是相连的领地</li>
</ul>
<p><strong>如果你说你要设计很奇怪的 Receptive Field,去解决很特别的问题,那完全是可以的,这都是你自己决定的</strong></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="simplification-1--typical-setting">Simplification 1 – Typical Setting<a href="#simplification-1--typical-setting" class="hash-link" aria-label="Direct link to Simplification 1 – Typical Setting" title="Direct link to Simplification 1 – Typical Setting">​</a></h3>
<p>虽然 Receptive Field 你可以任意设计,但也有<strong>最经典的 Receptive Field 的安排方式</strong></p>
<ol>
<li><strong>看所有的 Channel</strong></li>
</ol>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329162543905-ac0d6c592a9377ae1135c59e0402f1d4.png" width="699" height="423" class="img_ev3q"></p>
<p>一般在做影像辨识的时候我们可能,你可能不会觉得有些 Pattern 只出现某一个 Channel 裡面,所以会看全部的 Channel,所以既然会看全部的 Channel</p>
<p>我们在描述一个 Receptive Field 的时候,<strong>只要讲它的高跟宽就好</strong>了,就不用讲它的深度,反正<strong>深度一定是考虑全部的 Channel</strong>,而这个高跟宽合起来叫做 ==Kernel Size==</p>
<p>举例来说在这个例子裡面,我们的 Kernel Size 就是 3×3,那一般我们 Kernel Size 其实不会设太大,你在影像辨识裡面,往往做个 3×3 的 Kernel Size 就足够了,如果你说你设个 7×7  9×9,那这算是蛮大的 Kernel Size,一般往往都做 3×3</p>
<p>可能会有人疑问那如果 Kernel Size 都是 3×3,意味著说我们觉得在做影像辨识的时候,重要的 Pattern 都只在 3×3 这麼小的范围内,就可以被侦测出来了,听起来好像怪怪的,有些 Pattern 也许很大啊,也许 3×3 的范围没办法侦测出来啊</p>
<p>等一下我们会再回答这个问题,那我现在先告诉你说,常见的 Receptive Field 设定方式,就是 Kernel Size 3×3,然后<strong>一般同一个 Receptive Field,不会只有一个 Neuron 去关照它,往往会有一组 一排 Neuron 去守备它</strong>,比如说 64 个 或者是 128 个 Neuron 去守备一个 Receptive Field 的范围,</p>
<ol start="2">
<li>到目前為止我们讲的都是一个 Receptive Field,那各个不同 Receptive Field 之间的关係,是怎麼样呢,你会把你在最左上角的这个 Receptive Field,往右移一点,然后製造一个另外一个 Receptive Field,这个移动的量叫做 ==Stride==</li>
</ol>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329163013588-8509ed4750767237a64be0f41e2330e2.png" width="694" height="424" class="img_ev3q"></p>
<p>像在这个例子裡面 Stride 就等於 2,那 <strong>Stride 是一个你自己决定的 Hyperparameter</strong>,但这个 Stride 你往往不会设太大,往往设 1 或 2 就可  以了</p>
<p>因為你希望这些 Receptive Field,跟 Receptive Field 之间是有重叠的,因為假设 Receptive Field 完全没有重叠,那有一个 Pattern 就正好出现,在两个 Receptive Field 的交界上面,那就会变成没有任何 Neuron 去侦测它,那你也可能就会 Miss 掉这个 Pattern,所以我们希望 Receptive Field 彼此之间,有高度的重叠</p>
<p>那假设我们设 Stride = 2,那第一个 Receptive Field 就在这边,那第二个就会在这边</p>
<ol start="3">
<li>再往右移两格就放在这边,那这边就遇到一个问题了,它<strong>超出了影像的范围</strong>怎麼办呢</li>
</ol>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329163307529-e830e004890ac728ac3f47ece9ad6da1.png" width="695" height="435" class="img_ev3q"></p>
<p>那有人可能会说,那就不要在这边摆 Receptive Field,但你这样就漏掉了影像的边边的地方啊,如果有个 Pattern 就在边边的地方,你就没有 Neuron 去关照那些 Pattern啦,没有 Neuron 去侦测出现在边边的 Pattern 了,所以一般边边的地方也会考虑的,但超出范围了怎麼办呢</p>
<p>超出范围你就做 ==<strong>Padding</strong>==,<strong>Padding 就是补 0</strong>,好 所以如果你今天 Receptive Field 有一部分,超出影像的范围之外了,那就当做那个裡面的值都是 0</p>
<p>其实也有<strong>别的补值的方法,Padding 就是补值的意思</strong>,比如说有人会说,我这边不要补 0 好不好,我补整张图片裡面所有 Value 的平均,或者你说,我把边边的这些数字拿出来补，有各种不同的 Padding 的方法</p>
<ol start="4">
<li>那你<strong>除了这个横著移动,你也会这个直著移动</strong>,你有会有这个垂直方向上的移动,</li>
</ol>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329164727908-a01c434e7cc4fb34e4fdfccdc3861a41.png" width="754" height="438" class="img_ev3q"></p>
<p>在这边呢 我们一样垂直方向 Stride 也是设 2,所以你  有一个 Receptive Field 在这边,垂直方向移动两格,就有一个 Receptive Field 在这个地方,你就按照这个方式,扫过整张图片,所以整张图片裡面,每一吋土地都是有被某一个,Receptive Field 覆盖的,也就是图片裡面每一个位置,都有一群 Neuron 在侦测那个地方,有没有出现某些 Pattern</p>
<p>好 那这个是第一个简化,Fully Connected Network 的方式,好</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="observation-2">Observation 2<a href="#observation-2" class="hash-link" aria-label="Direct link to Observation 2" title="Direct link to Observation 2">​</a></h2>
<p>第二个观察就是,<strong>同样的 Pattern,它可能会出现在图片的不同区域裡面</strong>,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329182421998-e2828551fd35fdc82f34c2bc939c11f3.png" width="679" height="438" class="img_ev3q"></p>
<p>比如说鸟嘴这个 Pattern,它可能出现在图片的左上角,也可能出现在图片的中间,虽然它们的形状都是一样的 都是鸟嘴,但是它们可能出现在,图片裡面的不同的位置</p>
<p>按照我们刚才的讨论,你同样的 Pattern,出现在图片的不同的位置,似乎也不是太大的问题,因為出现在左上角的鸟嘴,它一定落在某一个 Receptive Field 裡面,因為 Receptive Field 是移动完之后会覆盖满整个图片的,所以图片裡面没有任何地方不是在某个 Neuron 的守备范围内</p>
<p>那假设在那个 Receptive Field 裡面,有一个 Neuron 它的工作,就是侦测鸟嘴的话,那鸟嘴就会被侦测出来</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329182937549-bf60022563e902b156a61ddbcd92df39.png" width="778" height="447" class="img_ev3q"></p>
<p>所以就算鸟嘴出现在中间,也没有关係,假设有 这边一定是在某一个,Receptive Field 的范围裡面,那个 Receptive Field,一定有一组 Neuron 在照顾,那假设其中有一个 Neuron,它可以侦测鸟嘴的话,那鸟嘴  出现在图片的中间,也会被侦测出来</p>
<p>但这边的问题是,这些侦测鸟嘴的 Neuron,它们做的事情其实是一样的,只是它们守备的范围是不一样,<strong>我们真的需要每一个守备范围,都去放一个侦测鸟嘴的 Neuron 吗？</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329183008609-f0e67c65f837a2764c609bada30ca2cd.png" width="782" height="436" class="img_ev3q"></p>
<p>如果不同的守备范围,都要有一个侦测鸟嘴的 Neuron,那你的参数量不会太多了吗？</p>
<p>而这个概念就好像為什麼教务处希望,可以推大型的课程一样,假设说每一个科系,其实都需要程式相关的课程,或每一个科系都需要机器学习相关的课程,那到底需不需要在每一个系所都开机器学习的课程,还是说开一个比较大班的课程,让所有系所的人都可以修课。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="simplification-2">Simplification 2<a href="#simplification-2" class="hash-link" aria-label="Direct link to Simplification 2" title="Direct link to Simplification 2">​</a></h2>
<p>如果放在影像处理上的话,我们能不能够让,不同 Receptive Field 的 Neuron共享参数,也就是做 ==Parameter Sharing权值共享==,那共享参数是什麼意思呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329183451096-8dc4e89f569321e305e5960621f91173.png" width="744" height="589" class="img_ev3q"></p>
<p>所谓共享参数就是,这<strong>两个 Neuron 它们的 weights完全是一样的</strong>,我这边特别用顏色来告诉你说,它们的 weights 完全是一样的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329185317890-947107ae9b7bf381e8c73a2b89d0de12.png" width="830" height="603" class="img_ev3q"></p>
<ul>
<li>
<p>上面这个 Neuron 的第一个 weight,叫做 w1,下面这个 Neuron 的第一个 weight 也是 w1,它们是同一个 weight,我用<strong>红色</strong>来表示</p>
</li>
<li>
<p>上面这个 Neuron 的第二个 weight 是 w2,下面这个 Neuron 的第二个 weight 也是w2,它们都用<strong>黄色</strong>来表示,以此类推</p>
</li>
</ul>
<p>上面这个 Neuron 跟下面这个 Neuron,<strong>它们守备的 Receptive Field 是不一样的,但是它们的参数是一模一样的</strong></p>
<p>那有人可能就会问说,欸 它的参数是一模一样,那它会不会输出永远都是一样？</p>
<p>不会,因為它们的<strong>输入是不一样</strong>的,这两个 Neuron 的参数一模一样,但是它们<strong>照顾的范围是不一样</strong>的</p>
<ul>
<li>
<p>上面这个 Neuron,我们说它的输入是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>,下面这个 Neuron它的输入是<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.2481em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span></span></span></span>,</p>
</li>
<li>
<p>上面这个 Neuron 的输出就是,x1 × w1 + x2 × w2,全部加加加 再加 Bias,然后透过 Activation Function 得到输出</p>
<span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="minner">……</span><span class="mclose">)</span></span></span></span></span>
</li>
<li>
<p>下面这个 Neuron 虽然也有 w1 w2,但 w1 跟 w2 是乘以 x1&#x27; x2&#x27;,所以它的<strong>输出不会跟上面这个 Neuron 一样</strong></p>
<span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0489em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="minner">……</span><span class="mclose">)</span></span></span></span></span>
</li>
</ul>
<p>所以两个 Neuron 守备的范围不一样,就算它们的参数一样,它们的输出也不会是一样的,所以这是第二个简化</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="simplification-2--typical-setting">Simplification 2 – Typical Setting<a href="#simplification-2--typical-setting" class="hash-link" aria-label="Direct link to Simplification 2 – Typical Setting" title="Direct link to Simplification 2 – Typical Setting">​</a></h3>
<p>我们让一些 Neuron 可以共享参数,那<strong>至於要怎麼共享,你完全可以自己决定,而这个是你可以自己决定的事情</strong>,但是接下来还是要告诉大家,<strong>常见的在影像辨识上面的共享的方法</strong>,是怎麼设定的</p>
<p>那我们刚才已经讲说,每一个 Receptive Field,它都有一组 Neuron 在负责守备</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329191138276-6b668f247ce9b6ff327b2eaae44cfb68.png" width="697" height="423" class="img_ev3q"></p>
<p>比如说 64 个 Neuron,所以这个 Receptive Field有 64 个 Neuron,这个 Receptive Field 也有 64 个 Neuron,那它们彼此之间会怎麼共享参数呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210329191243099-302d75c63822905e9621a0cd46836809.png" width="791" height="431" class="img_ev3q"></p>
<p>我们这边用一样的顏色,就代表说这两个 Neuron,共享一样的参数</p>
<p>所以其实<strong>每一个 Receptive Field都只有一组参数而已</strong>,就是</p>
<ul>
<li>左上边这个 Receptive Field 的第一个红色 Neuron,会跟右下边这个 Receptive Field 的第一个 红色Neuron 共用参数</li>
<li>它的第二个橙色 Neuron,跟它的第二个 橙色Neuron 共用参数</li>
<li>它的第三个绿色Neuron,跟它的第三个绿色 Neuron 共用参数</li>
<li>所以每一个 Receptive Field,都只有一组参数而已</li>
</ul>
<p>那这些参数有一个名字，叫做 ==Filter==,所以这两个红色 Neuron,它们共用同一组参数,这组参数就叫 Filter1,橙色这两个 Neuron 它们共同一组参数,这组参数就叫 Filter2 叫 Filter3 叫 Filter4,以此类推</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benefit-of-convolutional-layer">Benefit of Convolutional Layer<a href="#benefit-of-convolutional-layer" class="hash-link" aria-label="Direct link to Benefit of Convolutional Layer" title="Direct link to Benefit of Convolutional Layer">​</a></h2>
<p>目前已经讲了两个简化的方法,那我们来整理一下我们学到了什麼,这是 <strong>Fully Connected 的 Network</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330085040401-a38ad0fd4bece6bebe527399f5494250.png" width="765" height="404" class="img_ev3q"></p>
<p>它是<strong>弹性最大</strong>的,但有时候不需要看整张图片,也许<strong>只要看图片的一小部分</strong>就可以侦测出重要的 Pattern,所以我们有了 <strong>Receptive Field</strong> 的概念</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330085145465-c1376b3208ca278d639364e38c96b848.png" width="756" height="447" class="img_ev3q"></p>
<p>当我们强制一个 Neuron只能看一张图片裡面的一个范围的时候,它的<strong>弹性是变小</strong>的,如果是 Fully Connected 的 Network,它可以决定看整张图片，还是只看一个范围,就如果它只想看一个范围,就把很多 Weight 设成 0,就只看一个范围，所以加入 Receptive Field 以后,你的 Network 的弹性是变小的</p>
<p>接下来我们还有权值共享,权值共享又更进一步限制了 Network 的弹性</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330085417478-bb4519ea0522e370fd50554bf7095bf5.png" width="737" height="444" class="img_ev3q"></p>
<p>本来在 Learning 的时候,它可以决定这两个 Network 的参数要是什麼,每一个 Neuron 可以各自有不同的参数,它们可以正好学出一模一样的参数,也可以有不一样的参数</p>
<p>但是加入参数共享以后,就意味著说 某一些 Neuron参数要一模一样,所以这又更增加了对 Neuron 的限制,而 <strong>Receptive Field 加上 Parameter Sharing,就是 ==Convolutional Layer==</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330085630682-958a49261fc12b3215e5d3cbb02e6d61.png" width="788" height="442" class="img_ev3q"></p>
<p>有用到 Convolutional Layer 的 Network,就叫 Convolutional Neural Network,就是 CNN,所以从这个图上啊,你可以很明显地看出,其实 <strong>CNN 的 Bias 比较大,它的 Model 的 Bias 比较大</strong></p>
<p>可能有小伙伴会说 Model Bias 比较大 不是一件坏事吗？</p>
<p>Model Bias 大，不一定是坏事</p>
<ul>
<li>因為当 <strong>Model Bias 小,Model 的 Flexibility 很高</strong>的时候,它比较<strong>容易 Overfitting</strong>,Fully Connected Layer可以做各式各样的事情,它可以有各式各样的变化,但是它可能没有办法在,任何特定的任务上做好</li>
<li>而 Convolutional Layer,它是专门為影像设计的,刚才讲的 Receptive Field 参数共享,这些观察 都是為影像设计的,所以它在影像上仍然可以做得好,虽然它的 Model Bias 很大,但这个在影像上不是问题,但是如果它用在影像之外的任务,你就要仔细想想,那些任务有没有我们刚才讲的,影像用的特性</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="convolutional-layer">Convolutional Layer<a href="#convolutional-layer" class="hash-link" aria-label="Direct link to Convolutional Layer" title="Direct link to Convolutional Layer">​</a></h2>
<p>我们以上讲的,影像用的特性,其实是 CNN 的某一种介绍方式,那现在我们要讲另外一种介绍方式,第二种介绍方式跟刚才讲的介绍方式是一模一样的,只是同一个故事,用不同的版本来说明</p>
<p>第二个版本是,你比较常见的说明 CNN 的方式,假设第一个版本,你听得有点迷迷糊糊的话,那我们来听第二个版本</p>
<p>第二个版本是这样的,<strong>Convolutional 的 Layer 就是裡面有很多的 Filter</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330091401877-942b28fccd0d995ade1083f5c9f46b35.png" width="824" height="512" class="img_ev3q"></p>
<p>这些 Filter 啊 它们的大小是,3 × 3 × Channel 的 Size,如果今天是彩色图片的话,那就是 RGB 三个 Channel,如果是黑白的图片的话,它的 Channel 就等於 1</p>
<p><strong>一个 Convolutional 的 Layer 裡面就是有一排的 Filter</strong>,每一个 Filter ,它都是一个 3 × 3 × Channel,这麼大的 Tensor</p>
<p><strong>每一个 Filter 的作用就是要去图片裡面某一个 Pattern</strong>,当然这些 Pattern,要在 3 × 3 × Channel,那麼小的范围内啦,它才能够被这些 Filter 抓出来</p>
<p>那这些 Filter,怎麼去图片裡面抓 Pattern 的呢,我们现在举一个实际的例子</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330152604185-eeed0ab4d627d3e75ac9a841389291a0.png" width="778" height="556" class="img_ev3q"></p>
<p>例子裡面,我们假设 Channel 是 1,也就是说我们图片是<strong>黑白的图片</strong></p>
<p>那我们假设这些 Filter 的参数是已知的,Filter 就是一个一个的 Tensor,这个 Tensor 裡面的数值,我们都已经知道了,那实际上这些 Tensor 裡面的数值,其实就是 Model 裡面的 Parameter,这些 Filter 裡面的数值,<strong>其实是未知的,它 是要透过gradient decent去找出来的</strong></p>
<p>那我们现在已经假设这些 Filter 裡面的数值已经找出来了,我们来看看说这些 Filter,是怎麼跟一张图片进行运作,怎麼去图片上面把 Pattern 侦测出来的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330153005857-1daa26b75221987b748bc67f55b7697a.png" width="727" height="517" class="img_ev3q"></p>
<p>这是我们的图片,它是一个 6 × 6 的大小的图片,那这些 Filter的做法就是,先把 Filter 放在图片的左上角,然后<strong>把 Filter 裡面所有的值,跟左上角这个范围内的 9 个值做相乘</strong>,也就是把这个 Filter 裡面的 9 个值,跟这个范围裡面的 9 个值呢,做 Inner Product,做完是 3</p>
<p>==注意！在此处卷集运算中，老师讲的<strong>内积</strong>，<strong>不要理解为</strong>线性代数中<strong>矩阵的乘法</strong>，而是<strong>filter</strong>跟<strong>图片对应位置</strong>的数值<strong>直接相乘</strong>，所有的都乘完以后<strong>再相加</strong>==</p>
<p>老师用的filter为<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span></span></span></span>  与图片的第一个<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span>矩阵<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span></span></span></span> 做卷积运算的过程为</p>
<p><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></p>
<p>在下图中 filter为<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span></span></span></span>  大家可以自行验证</p>
<img decoding="async" loading="lazy" src="https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-juanji.gif" style="zoom:50%" class="img_ev3q">
<p>接下来这个 Filter 呢,本来放在左上角,接下来就往右移一点,那这个移动的距离叫做 ==Stride==</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330154900422-7972ef197cc9835ac9b6bcd50a4b1f13.png" width="731" height="508" class="img_ev3q"></p>
<p>那在刚才讲前一个版本的故事的时候,我们的 Stride 是设 2,那在这个版本的故事裡面,我们 Stride 就设為 1,那往右移一点,然后再把这个 Filter,跟这个范围裡面的数值,算 Inner Product 算出来是 -1</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330155019300-5ebcd16d6d881a96a2ef84b31ee9b66a.png" width="738" height="561" class="img_ev3q"></p>
<p>然后就以此类推,再往右移一点 再算一下,然后这边全部扫完以后,就往下移一点 再算一下,以此类推,一直到把这个 Filter 放在右下角,算出一个数值,答案就是 -1 就这样</p>
<p>这个 Filter 怎麼说它在侦测 Pattern 呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330155357311-b9953dfe51544fd71fa0f419b998dae5.png" width="730" height="551" class="img_ev3q"></p>
<p>你看这个 Filter 裡面,它<strong>对角线的地方都是1</strong>,所以它看到 Image 裡面也出现连三个 1 的时候,它的数值会最大</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330155504450-02fb863ca0b1b562bb44c880bb4a5273.png" width="732" height="547" class="img_ev3q"></p>
<p>所以你会发现左上角的地方的值最大,左下角的地方的值最大,就告诉我们说,这个图片裡面左上角有出现 3,左上角有出现这个 Pattern,左下角有出现这个,三个 1 连在一起的 Pattern,这个是第一个 Filter</p>
<p>好 那接下来呢,我们把每一个 Filter,都做重复的 Process,比如说这边有第二个 Filter</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330155805207-cebcd5afeaca8be3952ec655ea737aef.png" width="741" height="545" class="img_ev3q"></p>
<p>我们就把第二个 Filter,先从左上角开始扫起,得到一个数值,往右移一点 再得到一个数值,再往右移一点 再得到一个数值,反覆同样的 Process,反覆同样的操作,直到把整张图片都扫完,我们又得到另外一群数值</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330161012801-371961b7ee59da2c11b376ec46faffde.png" width="744" height="573" class="img_ev3q"></p>
<p>所以每一个 Filter,都会给我们一群数字,红色的 Filter 给我们一群数字,蓝色的 Filter 给我们一群数字,如果我们有 64 个 Filter,我们就得到 64 群的数字了,那这一群数字啊,它又有一个名字,它叫做 ==Feature Map==</p>
<p>所以当我们把一张图片,通过一个 Convolutional Layer,裡面有一堆 Filter 的时候,我们產生出来了一个 Feature Map</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330161229506-3ef37e8fae3855b3e485fed82ed59513.png" width="782" height="601" class="img_ev3q"></p>
<p>那假设这个 Convolutional Layer裡面,它有 64 个 Filter,那我们產生出来64个 Feature Map,每一组在这个例子裡面是 4 × 4，这个 <strong>Feature Map你可以看成是,另外一张新的图片</strong></p>
<p>只是这个图片的 Channel 它有 64 个,而且这并不是 RGB 这个图片的 Channel,在这里<strong>每一个 Channel 就对应到一个 Filter</strong>,本来一张图片它三个 Channel,通过一个 Convolution,它变成一张新的图片,有 64 个 Channel</p>
<p>这个 <strong>Convolutional Layer 是可以叠很多层的</strong>,刚才是叠了第一层,那如果叠第二层会发生什麼事呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330161535127-33e86a868bdc97bc3148402d82f417f6.png" width="804" height="620" class="img_ev3q"></p>
<p><strong>第二层的 Convolution</strong> 裡面,也有一堆的 Filter,那每一个 Filter 呢,它的大小我们这边也设 3 × 3,那<strong>它的高度必须设為 64</strong></p>
<p><strong>Filter 的这个高度就是它要处理的影像的 Channel</strong>,所以跟刚才第一层的 Convolution,假设输入的影像是黑白的 Channel是 1,那我们的 Filter 的高度就是 1,输入的影像如果是彩色的 Channel 是 3,那 Filter 的高度就是 3,那在第二层裡面,我们也会得到一张影像,对第二个 Convolutional Layer 来说,它的输入也是一张图片,那这个图片的 Channel 是多少,这个图片的 Channel 是 64</p>
<p>这个 64 是前一个 Convolutional Layer 的,Filter 数目,前一个 Convolutional Layer,它 Filter 数目 64,那输出以后就是 64 个 Channel</p>
<p><strong>如果我们的 Filter 的大小一直设 3 × 3,会不会让我们的 Network,没有办法看比较大范围的 Pattern 呢</strong></p>
<p>其实不会的,因為你想想看,如果我们在第二层 Convolutional Layer,我们的 Filter 的大小一样设 3 × 3 的话,会发生什麼事情呢</p>
<p>如果我们一样设 3 × 3 的话,当我们看最左上角这个数值的时候,最左上角这个数值在影像上,其实是对应到这个范围,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330162504718-854215c5f51871cb7db535b4482b9bc8.png" width="350" height="627" class="img_ev3q"></p>
<p>右下角的数值在影像上,其实是对应到这个范围,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330162532833-5f1c6cb6962595d5c70f3e0e7e6765d4.png" width="338" height="630" class="img_ev3q"></p>
<p>所以当我们看这 3 × 3 的范围的时候,和第一个 Convolutional Layer 的输出的,这个 Feature Map 的,3 × 3 的范围的时候,我们在原来的影像上,其实是考虑了一个 5 × 5 的范围</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330162621285-c4e2366958c9902907d96b7afbde56a9.png" width="743" height="635" class="img_ev3q"></p>
<p>所以虽然我们的 Filter 只有 3 × 3,但它在影像上考虑的范围,是比较大的 是 5 × 5,所以今天你的 N<strong>etwork 叠得越深,同样是 3 × 3 的大小的 Filter,它看的范围就会越来越大</strong>,所以 Network 够深,你不用怕你侦测不到比较大的 Pattern,它还是可以侦测到比较大的 Pattern</p>
<p>刚才我们讲了两个版本的故事了,那这两个版本的故事,是一模一样的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330163033020-69a0d68c257683b7c5158178b1be7fc1.png" width="768" height="500" class="img_ev3q"></p>
<p>我们在第一个版本的故事裡面,说到了有一些 Neuron,这些 Neuron 会共用参数,这些<strong>共用的参数,就是第二个版本的故事裡面的 Filter</strong></p>
<p>我们这个 Filter 裡面有 3 × 3 × 3个数字,我这边特别还<strong>用顏色,把这些数字圈起来,告诉你说 这个 Weight 就是这个数字</strong></p>
<p>以此类推,那这边我把 Bias 去掉了, Neuron 这个是有 Bias 的,这个 Filter 有没有 Bias 呢,其实是有的,只是在刚才的故事裡面没有提到,在一般的这个实作上,你的 CNN 的这些 Filter,其实都还是有那个 Bias 的数值的</p>
<p>在刚才第一个版本的故事裡面,我们说不同的 Neuron,它们可以 Share Weight,然后去守备不同的范围,而 <strong>Share Weight 这件事,其实就是我们把 Filter 扫过一张图片</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330163810316-6e9ba043ae84d3e830c49cc07b1e4485.png" width="749" height="608" class="img_ev3q"></p>
<p>那把 F<strong>ilter 扫过一张图片这件事,其实就是 Convolution</strong>,这就是為什麼 Convolutional Layer,要叫 Convolutional Layer 的关係</p>
<p>那所谓的把 Filter 扫过图片这件事情,其实就是不同的 Receptive Field,Neuron 可以共用参数,而这组共用的参数,就叫做一个 Filter</p>
<p>今天特别从两个不同的面向,讲 CNN 这个东西,希望可以帮助你对 CNN 有更深地了解</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330164622894-0e5b37a6dc7d098fb0410e0ebb83c280.png" width="756" height="524" class="img_ev3q"></p>
<p>為什麼用 CNN 是基於两个观察</p>
<ul>
<li>第一个观察是 我们不需要看整张图片,那对 Neuron 的故事版本,对於第一个故事而言就是,Neuron 只看图片的一小部分,对 Filter 的故事而言就是,我们有一组 Filter,每个 Filter 只看一个小范围,它只侦测小的 Pattern</li>
<li>然后我们说 同样的 Pattern,可能出现在图片的不同的地方,所以 Neuron 间可以共用参数,对 Filter 的故事而言就是,一个 Filter 要扫过整张图片,这个就是 Convolutional Layer</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="observation-3">Observation 3<a href="#observation-3" class="hash-link" aria-label="Direct link to Observation 3" title="Direct link to Observation 3">​</a></h2>
<p>Convolutional Layer,在做影像辨识的时候呢,其实还有第三个常用的东西,这个东西呢 叫做 Pooling,那 Pooling 是怎麼来的呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330164857135-2dc9f2d9d3614af07ddcfed04670bb62.png" width="718" height="370" class="img_ev3q"></p>
<p>Pooling 来自於另外一个观察</p>
<p>我们把一张比较大的图片做 Subsampling,举例来说你把偶数的 Column 都拿掉,奇数的 Row 都拿掉,图片变成為原来的1/4,但是不会影响裡面是什麼东西,把一张大的图片缩小,这是一隻鸟,这张小的图片看起来还是一隻鸟</p>
<p>那所以呢 有了Pooling 这样的设计,那 Pooling 是怎麼运作的呢</p>
<p>Pooling 这个东西啊,它本身没有参数,所以它不是一个 Layer,它裡面没有 Weight,它没有要 Learn 的东西,所以有人会告诉你说 Pooling 比较像是一个 Activation Function,比较像是 Sigmoid ， ReLU 那些,因為它裡面是没有要 Learn 的东西的,它就是一个 Operator,它的行為都是固定好的,没有要根据 Data 学任何东西</p>
<p>那 Pooling 其实也有很多不同的版本,我们这边讲的是 Max Pooling</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330165950177-950b37817946702d7aed42d9fc6044a7.png" width="731" height="564" class="img_ev3q"></p>
<p>刚才说每一个 Filter 都產生一把数字,要做 Pooling 的时候,我们就把这些数字几个几个一组,比如说在这个例子裡面就是 2×2 个一组,每一组裡面选一个代表,在 Max Pooling 裡面,我们选的代表就是<strong>最大的那一个</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330170356117-81e501dd4e9325dc38198813729491f7.png" width="734" height="557" class="img_ev3q"></p>
<p>你不一定要选最大的那一个,这个是你自己可以决定的,Max Pooling 这一个方法是选最大的那一个,但是也有 average Pooling ，就是选平均嘛,还有选几何平均的,所以有各式各样的 Pooling 的方法</p>
<p>也一定要 2×2 个一组吗,这个也是你自己决定的,你要 3×3 4×4 也可以</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="convolutional-layers--pooling">Convolutional Layers + Pooling<a href="#convolutional-layers--pooling" class="hash-link" aria-label="Direct link to Convolutional Layers + Pooling" title="Direct link to Convolutional Layers + Pooling">​</a></h2>
<p>所以我们做完 Convolution 以后,往往后面还会搭配 Pooling,那 <strong>Pooling 做的事情就是把图片变小</strong>,做完 Convolution 以后我们会得到一张图片,这一张图片  裡面有很多的 Channel,那做完 Pooling 以后,我们就是把这张图片的 Channel 不变,本来 64 个 Channel 还是 64 个 Channel,但是我们会把图片变得比较狭长一点</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330170700272-e5248d39ddd2dc6cf3f9db684c9d56f4.png" width="564" height="442" class="img_ev3q"></p>
<p>在刚才的例子裡面,本来 4×4 的图片,如果我们把这个 Output 的数值啊,2×2 个一组的话,那 4×4 的图片就会变成 2×2 的图片,这个就是 Pooling 所做的事情</p>
<p><strong>那一般在实作上啊,往往就是 Convolution 跟 Pooling 交替使用</strong>,就是你可能做几次 Convolution,做一次 Pooling,比如两次 Convolution 一次 Pooling,两次 Convolution 一次 Pooling</p>
<p>不过你可以想见说 <strong>Pooling,对於你的 Performance,还是可能会带来一点伤害的</strong>,因為假设你今天要侦测的是非常微细的东西,那你随便做 Subsampling,Performance 可能会稍微差一点</p>
<p>所以近年来你会发现,很多影像电视的 Network 的设计,往往也开始把 Pooling 丢掉,他会做这种,Full Convolution 的 Neural Network,就整个 Network 裡面统统都是 Convolution,完全都不用 Pooling</p>
<p>那是因為近年来运算能力越来越强,Pooling 最主要的理由是為了减少运算量,做 Subsampling,把影像变少 减少运算量,那如果你今天你的运算资源,足够支撑你不做 Pooling 的话,很多 Network 的架构的设计,往往今天就不做 Pooling,全 Convolution,Convolution 从头到尾,然后看看做不做得起来,看看能不能做得更好</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-whole-cnn">The whole CNN<a href="#the-whole-cnn" class="hash-link" aria-label="Direct link to The whole CNN" title="Direct link to The whole CNN">​</a></h3>
<p>那一般以后,你的架构就是 Convolution 加 Pooling,那我刚才讲过说 Pooling 是可有可无啦,今天很多人可能会选择不用 Pooling,好 那如果你做完几次 Convolution 以后,接下来呢,最终怎麼得到最后的结果呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330171219295-a66ca87e37a76f03dfc349f439d95c2c.png" width="664" height="610" class="img_ev3q"></p>
<p>你会把 Pooling 的 Output 做一件事情,叫做 Flatten,Flatten 的意思就是,把这个影像裡面啊,本来排成矩阵的样子的东西拉直,把所有的数值拉直变成一个向量,再把这个向量,丢进 Fully Connected 的 Layer 裡面</p>
<p>最终你可能还要过个 Softmax,然后最终得到影像辨识的结果,这就是一个经典的影像辨识的Network,它可能有的样子就是长这样,裡面有 Convolution,有 Pooling 有 Flatten,最后再通过几个,Fully Connected 的 Layer 或 Softmax,最终得到影像辨识的结果</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="application-alpha-go">Application： Alpha Go<a href="#application-alpha-go" class="hash-link" aria-label="Direct link to Application： Alpha Go" title="Direct link to Application： Alpha Go">​</a></h2>
<p>那除了影像辨识以外啊,你可能听过 CNN 另外一个最常见的,最耳熟能详的应用,就是用来下围棋,那今天呢 如果讲个机器学习的课,没有提到 AlphaGo,大家就觉得你什麼都没有讲对不对,所以我们来提一下 AlphaGo,好 怎麼用这个 CNN 来下围棋呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330171913676-173811908c13bb0c8dda4b83812bf5e8.png" width="690" height="281" class="img_ev3q"></p>
<p>我们说下围棋其实就是一个分类的问题,你的 Network 的输入,是棋盘上黑子跟白子的位置,你的输出就是下一步应该要落子的位置</p>
<p>可是我们今天已经知道说,Network 的输入就是一个向量啊,那<strong>怎麼把棋盘表示成一个向量</strong>呢,完全没有问题,棋盘上就是有 19 × 19 个位置嘛,那我们就把一个棋盘,表示成一个 19 × 19 维的向量,在这个向量裡面,如果某一个位置有一 个黑子,那那个位置我们就填 1,如果白子我们就填 -1,如果没有子我们就填 0</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330172015868-87fd3cd38188e9aa35203e380e541be0.png" width="728" height="441" class="img_ev3q"></p>
<p>我们就可以告诉 Network 说,现在棋盘上的盘势长什麼样,我们可以用一个 19 × 19 维的向量,来描述一个棋盘,当然这不一定是要这麼做啦,不一定要黑子是 1 白子是 -1,然后没有子就是 0,这只是一个可能的表示方式而已,你们可以想出其他更神奇的表示方式,总之我们有办法把棋盘上的盘势,用一个向量来描述</p>
<p>把这个向量输到一个 Network 裡面,然后呢,你就可以把下围棋当作一个分类的问题,叫这个 Network 去预测,下一步应该落子的位置落在哪裡最好</p>
<p>所以下围棋,就是一个有 19 × 19 个类别的分类的问题,Network 会 Output 说,在这 19 × 19 个类别裡面,哪一个类别是最好的,应该要选择下一步落子的位置应该在哪裡,那这个问题完全可以用一个,Fully Connected 的 Network 来解决,但是用 <strong>CNN 的效果更好</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330172138162-04f6aa3b88ade98f4634cebbe474136f.png" width="807" height="453" class="img_ev3q"></p>
<p>為什麼用 CNN 的效果更好呢,首先你完全可以把一个棋盘,看作是一张图片,一个棋盘,可以看作是一个解析度 19 × 19 的图片,一般图片很大,一般图片可能都 100 × 100 的解析度,都是很小的图片了啊,但是棋盘是一个更小的图片,这个图片它的解析度只有 19 × 19,这个图片裡面每一个像素 每一个 Pixel,就代表棋盘上一个可以落子的位置</p>
<p>那 Channel 呢,一般图片的 Channel 就是 RGB 嘛,RGB 代表一个顏色,那棋盘上每一个 Pixel 的 Channel,应该是什麼呢</p>
<p>在 AlphaGo 的原始论文裡面它告诉你说,每一个棋盘的位置,<strong>每一个棋盘 上的 Pixel,它是用 48 个 Channel 来描述</strong>,也就是说棋盘上的每一个位置,它都用 48 个数字,来描述那个位置发生了什麼事</p>
<p>那至於為什麼是这 48 个,那这个显然是围棋高手设计出来的,那 48 个位置包括,比如说 啊 这个位置是不是要被叫吃了,这个位置旁边有没有顏色不一样的等等,就是这样子描述每一个位置,所以你会用 48 个数字,来描述棋盘上的一个位置,这一个棋盘它就是 19 × 19 的解析度的图片,它的 Channel 就是 48,</p>
<p>但是為什麼 CNN 可以用在下围棋上呢,我们刚才就有强调说 <strong>CNN ,其实并不是你随便用都会好的,它是為影像设计的</strong>,所以如果一个问题,它跟影像没有什麼共通的特性的话,你其实不该用 CNN,所以今天既然在下围棋可以用 CNN,那意味著什麼,那意味著围棋跟影像有共同的特性,什麼样共同的特性呢</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-cnn-for-go-playing">Why CNN for Go playing?<a href="#why-cnn-for-go-playing" class="hash-link" aria-label="Direct link to Why CNN for Go playing?" title="Direct link to Why CNN for Go playing?">​</a></h3>
<p>我们刚才讲说在影像上的<strong>第一个观察</strong>是,很多重要的 Pattern,你只需要看小范围就知道,下围棋是不是也是一样呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330172519672-207e1f05d830fe6417598b0fd67a0b9e.png" width="694" height="284" class="img_ev3q"></p>
<p>举例来说这一个 Pattern,你就算<strong>不用看整个棋盘的盘势,你都知道说这边发生了什麼事</strong>,这个就是白子被黑子围住了嘛,那接下来黑子如果放在这边,就可以把白子提走,那白子要放在这边才不会,才可以接这个白子 才不会被提走,那其实在 AlphaGo 裡面啊,它的第一层的 Layer,它的 Filter 的大小就是 5 × 5,所以显然在设计这个 Network 的人觉得说,棋盘上很多重要的 Pattern,  也许看 5 × 5 的范围就可以知道了</p>
<p>再来是我们说影像上的<strong>第二个观察</strong>是,同样的 Pattern 可能会出现在不同的位置,在下围棋裡面是不是也是一样呢,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330172624575-16a95a3772ac41029b2f5cf0801e955f.png" width="701" height="440" class="img_ev3q"></p>
<p>这个叫吃的 Pattern,它可以出现在棋盘上的任何位置,它可以出现在左上角,也可以出现在右下角,所以从这个观点来看,影像跟下围棋有很多共同之处</p>
<p>但是让人想不透的地方是,在做影像的时候我们说我们都会做 Pooling,也就是一张<strong>影像做 Subsampling 以后,并不会影响我们对影像中物件的判读</strong></p>
<p>但是棋盘是这个样子吗,你可以把棋盘上的奇数行跟偶数列拿掉,还是同一个棋局吗,听起来好像不是对不对,下围棋这麼精细的任务,你随便拿掉一个 Column 拿掉一个 Row,整个棋整个局势就不一样啦,怎麼可能拿掉一个 Row 拿掉一个 Column,还会没有问题呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330172912802-a2e2244a2e45c526bdf81ffd1d1ca099.png" width="708" height="98" class="img_ev3q"></p>
<p>所以有人就会说,啊 CNN 裡面就是要有 Pooling,然后影像辨识都是用 Pooling,所以 AlphaGo 也一定有用 Pooling,所以代表 AlphaGo 很烂啊,针对 Pooling 这个弱点去攻击它,一定就可以把它打爆,真的是这样吗</p>
<p>可是 AlphaGo 又这麼强,显然它没有这麼显而易见的弱点,所以这个问题就让我有点困扰,好 但后来我就去仔细读了一下,AlphaGo 那篇 Paper</p>
<p>其实 AlphaGo 在 Nature 上的 Paper,其实没有多长,大概就,我记得就五 六页而已,所以其实你一下子就可以看完了,而且在这个文章的正文裡面,甚至没有提它用的网路架构是什麼样子,它没有讲 Network 架构的细节,这个细节在哪裡呢,这个细节在附件裡  面,所以我就仔细读了一下附件,看看说 AlphaGo 的网路结构长什麼样子</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330183705782-c29dbc8fe60816197d8c0429e1486d64.png" width="861" height="466" class="img_ev3q"></p>
<p>我们就来看一下,这个附件裡面是怎麼描述,AlphaGo 的类神经网路结构的,它先说呢</p>
<ul>
<li>我们把一个棋盘,看作 19 × 19 × 48 那麼大小的 Image</li>
<li>接下来它说它有做 Zero Padding,Padding 这件事我们有讲嘛,就是你的 Filter 如果超出影像的范围就补 0,Zero Padding 就是超出范围就补 0 的意思</li>
<li>它说它的 Filter 的大小啊,Kernel Size 就是 Filter 的大小是 5 × 5</li>
<li>然后有 k 个 Filter,k 是多少,k 是 192,这当然是试出来的啦,它也试了 128 跟 256 发现 192 最好了,好 这是第一层</li>
<li>然后 Stride=1,Stride 是什麼 我们刚才也解释过了</li>
<li>然后这边有用了 Rectifier Nonlinearity,这是什麼,这个就是 ReLU 啦,这个就是 ReLU</li>
<li>然后在第二层呢,到第 12 层都有做 Zero Padding,然后呢 这个 Kernel Size 都是 3 × 3,一样是 k 个 Filter,也就是每一层都是 192 个 Filter,Stride 呢 一样设 1,就这样叠了很多层以后呢,因為是一个分类的问题</li>
<li>最后加上了一个 Softmax</li>
</ul>
<p>读完以后你有发现什麼玄机吗,发现它==没有用 Pooling==</p>
<p>所以这给我们一个很好的例子就是,类神经网路的设计这个==应用之道,存乎一心==</p>
<p>你不要看影像上面都有用 Pooling,就觉得 Pooling 一定是好的,在下围棋的时候就是不适合用 Pooling,所以你要想清楚说,你今天用一个 Network 架构的时候,我这个 Network 的架构到底代表什麼意思,它适不适合用在我现在这个任务上,</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="more-applications">More Applications<a href="#more-applications" class="hash-link" aria-label="Direct link to More Applications" title="Direct link to More Applications">​</a></h3>
<p>而那 CNN 呢,除了下围棋还有影像以外,欸 近年来也用在语音上,也用在文字处理上,这边我们就不再细讲</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330184018834-f8332af8730bf11915e9ddc39cbd865e.png" width="812" height="611" class="img_ev3q"></p>
<p>但是呢 你如果你真的想把 CNN 用在语音上,用在这个文字处理上,你要仔细看一下文献上的方法</p>
<p>这个在影像 在语音上,在文字上,那个 Receptive Field 的设计啊,这个参数共享的设计啊,跟影像上不是一样的</p>
<p>所以你要想清楚,那些 Receptive Field 用在语音,用在文字上的设计跟影像上不是一样,是考虑了语音跟文字的特性以后所设计的</p>
<p>所以你不要以為在影像上的 CNN,直接套到语音上它也 Work,可能是不 Work 的,你要想清楚说影像,语音有什麼样的特性,那你要怎麼设计合适的 Receptive Field,</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="to-learn-more">To learn more<a href="#to-learn-more" class="hash-link" aria-label="Direct link to To learn more" title="Direct link to To learn more">​</a></h3>
<p>有人会说 CNN,其实 CNN,它没有办法处理影像放大缩小,或者是旋转的问题,怎麼说呢,假设今天你给 CNN 看的狗都是这个大小,它可以辨识说这是一隻狗,当你把这个图片放大的时候,它可以辨识说牠还是一隻狗吗,可能是不行的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210330184237888-7183fd7f8ac7ea5bdbf6dba4c5b72a7b.png" width="715" height="458" class="img_ev3q"></p>
<p>你可能会想说 欸怎麼会不能够辨识呢,这两个形状不是一模一样啊,怎麼放大就不能辨识呢,CNN 这麼笨吗</p>
<p>它就是这麼笨,对它来说这两张图片,虽然这个形状是一模一样的,但是如果你把它拉长成向量的话,它裡面的数值就是不一样的啊,所以对 CNN 来说,虽然你人眼一看觉得它形状很像,但对 CNN 的 Network 来说它是非常不一样</p>
<p>所以事实上,CNN 并不能够处理影像放大缩小,或者是旋转的问题,当它今天在某种大小的影像上,假设你裡面的物件都是比较小的,它在上面学会做影像辨识,你把物件放大它就会整个惨掉</p>
<p>所以 CNN 并没有你想像的那麼强,那就是為什麼在做影像辨识的时候,往往都要做 ==Data Augmentation==,所谓 Data Augmentation 的意思就是说,你把你的训练资料,每张图片都裡面截一小块出来放大,让 CNN 有看过不同大小的 Pattern,然后把图片旋转,让它有看过说,某一个物件旋转以后长什麼样子,CNN 才会做到好的结果</p>
<p>那你说 欸 CNN 这个不能够处理 Scaling,跟 Rotation 的问题啊,那有没有什麼 Network 架构,是可以处理这个问题呢,其实有的,有一个架构叫 <strong>Special Transformer Layer</strong>,我们不会讲它,就把它的这个录影的连结放在这边,给大家参考</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#image-classification" class="table-of-contents__link toc-highlight">Image Classification</a></li><li><a href="#observation-1" class="table-of-contents__link toc-highlight">Observation 1</a></li><li><a href="#simplification-1" class="table-of-contents__link toc-highlight">Simplification 1</a><ul><li><a href="#simplification-1--typical-setting" class="table-of-contents__link toc-highlight">Simplification 1 – Typical Setting</a></li></ul></li><li><a href="#observation-2" class="table-of-contents__link toc-highlight">Observation 2</a></li><li><a href="#simplification-2" class="table-of-contents__link toc-highlight">Simplification 2</a><ul><li><a href="#simplification-2--typical-setting" class="table-of-contents__link toc-highlight">Simplification 2 – Typical Setting</a></li></ul></li><li><a href="#benefit-of-convolutional-layer" class="table-of-contents__link toc-highlight">Benefit of Convolutional Layer</a></li><li><a href="#convolutional-layer" class="table-of-contents__link toc-highlight">Convolutional Layer</a></li><li><a href="#observation-3" class="table-of-contents__link toc-highlight">Observation 3</a></li><li><a href="#convolutional-layers--pooling" class="table-of-contents__link toc-highlight">Convolutional Layers + Pooling</a><ul><li><a href="#the-whole-cnn" class="table-of-contents__link toc-highlight">The whole CNN</a></li></ul></li><li><a href="#application-alpha-go" class="table-of-contents__link toc-highlight">Application： Alpha Go</a><ul><li><a href="#why-cnn-for-go-playing" class="table-of-contents__link toc-highlight">Why CNN for Go playing?</a></li><li><a href="#more-applications" class="table-of-contents__link toc-highlight">More Applications</a></li><li><a href="#to-learn-more" class="table-of-contents__link toc-highlight">To learn more</a></li></ul></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>