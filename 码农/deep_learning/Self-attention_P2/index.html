<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-码农/deep_learning/Self-attention_P2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Self-attention_P2 | Coisini</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://doc.minddiy.top/码农/deep_learning/Self-attention_P2/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Self-attention_P2 | Coisini"><meta data-rh="true" name="description" content="从这一排 vector 得到 $b^1$,跟从这一排 vector 得到 $b^2$,它的操作是一模一样的.要强调一点是,这边的 $b^1$ 到 $b^4$,它们并不需要依序產生,它们是一次同时被计算出来的"><meta data-rh="true" property="og:description" content="从这一排 vector 得到 $b^1$,跟从这一排 vector 得到 $b^2$,它的操作是一模一样的.要强调一点是,这边的 $b^1$ 到 $b^4$,它们并不需要依序產生,它们是一次同时被计算出来的"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://doc.minddiy.top/码农/deep_learning/Self-attention_P2/"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/Self-attention_P2/" hreflang="en"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/Self-attention_P2/" hreflang="x-default"><meta name="google-site-verification" content="1FUPX6Qo4y3ecU623ShEurhgnjhSTjK49rRMhEDlzFA">
<link rel="stylesheet" href="/katex/katex.min.css">
<script src="/js/matomo.js" async defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.79037026.css">
<script src="/assets/js/runtime~main.468f2b27.js" defer="defer"></script>
<script src="/assets/js/main.4763ab3e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Coisini</b></a></div><div class="navbar__items navbar__items--right"><a href="https://minddiy.top" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Main site<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Self-attention_P2</h1></header>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409092350116-7670a010c19af04321430a1301a8f537.png" width="580" height="429" class="img_ev3q"></p>
<p>从这一排 vector 得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>,跟从这一排 vector 得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,它的操作是一模一样的.要强调一点是,这边的 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,它们并<strong>不需要依序產生</strong>,它们是一次同时被计算出来的</p>
<p>怎麼计算这个 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>？我们现在的主角,就变成 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409093744204-92bd31370d941ecbd6bb21d28e4f0b09.png" width="786" height="327" class="img_ev3q"></p>
<ul>
<li>
<p>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 乘上一个 matrix,变成 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>
<p>然后接下来根据 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,去对<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 这四个位置,都去计算 attention 的 score</p>
<ul>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 做个这个 dot product</li>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 也做个 dot product</li>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> 也做 dot product</li>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 也做 dot product,得到四个分数</li>
</ul>
</li>
<li>
<p>得到这四个分数以后,可能还会做一个 normalization,比如说 softmax,然后得到最后的 attention 的 score,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1361em;vertical-align:-0.3842em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">3</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">4</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span></span></span></span>那我们这边用 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>表示经过 normalization 以后的attention score</p>
</li>
<li>
<p>接下来拿这四个数值,分别乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409094148657-b53fc2c5bf372d28906666e53294ac09.png" width="819" height="517" class="img_ev3q"></p>
<ul>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1361em;vertical-align:-0.3842em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span></span></span></span>乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></li>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1361em;vertical-align:-0.3842em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span></span></span></span> 乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1361em;vertical-align:-0.3842em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">3</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span></span></span></span> 乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></li>
<li>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1361em;vertical-align:-0.3842em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">4</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3842em"><span></span></span></span></span></span></span></span></span></span> 乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,然后全部加起来就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8641em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-2.453em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8747em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span></span>
</li>
</ul>
<p>同理就可以,由 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> 乘一个 transform 得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>,然后就计算 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>,从 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 乘一个 transform 得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,就计算 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,以上说的是  Self-attention 它运作的过程</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="矩阵的角度">矩阵的角度<a href="#矩阵的角度" class="hash-link" aria-label="Direct link to 矩阵的角度" title="Direct link to 矩阵的角度">​</a></h2>
<p>接下来我们从矩阵乘法的角度,再重新讲一次我们刚才讲的,Self-attention 是怎麼运作的</p>
<p>我们现在已经知道每一个 a 都產生 q k v</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409100334528-b6c2031ff8c2ec49c8c0dbf4f9c903c5.png" width="786" height="184" class="img_ev3q"></p>
<p>如果要用矩阵运算表示这个操作的话,是什麼样子呢</p>
<p>我们每一个 a,都乘上一个矩阵,我们这边用 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span> 来表示它,得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0191em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>,每一个 a 都要乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span>,得到<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0191em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>,<strong>这些不同的 a 你可以把它合起来,当作一个矩阵来看待</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409100755718-5bb6b4ed6bcbf4027a500df2e257c1aa.png" width="547" height="106" class="img_ev3q"></p>
<p>一样<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>也都乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span> 得到<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,那你可以<strong>把 a1 到 a4 拼起来</strong>,看作是一个矩阵,这个矩阵我们用 I 来表示，这个矩阵的四个 column 就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span></span></span></span> 乘上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span> 就得到另外一个矩阵,我们用 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span> 来表示它,这个 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span> 就是把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 这四个 vector 拼起来,就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span> 的四个 column</p>
<p>所以我们从 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,得到  <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>这个操作,其实就是<strong>把 I 这个矩阵,乘上另外一个矩阵 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span>，得到矩阵<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span></strong>。<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span></span></span></span> 这个矩阵它裡面的 column就是我们 Self-attention 的 input是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>；<strong><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span>其实是 network 的参数,它是等一下会被learn出来的</strong> ；<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span> 的四个 column,就是  <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></p>
<p>接下来產生 k 跟 v 的操作跟 q 是一模一样的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409101331347-6ee2b05c672b0c42d17cfdc5f9ff50bd.png" width="555" height="331" class="img_ev3q"></p>
<p>所以每一个 a 得到 q k v ,其实就是把输入的这个,vector sequence 乘上三个不同的矩阵,你就得到了 q,得到了 k,跟得到了 v</p>
<p>下一步是,每一个 q 都会去跟每一个 k,去计算这个 inner product,去<strong>得到这个 attention 的分数</strong></p>
<p>那得到 attention 分数这一件事情,如果从矩阵操作的角度来看,它在做什麼样的事情呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409102703364-19a448f683725c4ace2dab52d5975af9.png" width="805" height="369" class="img_ev3q"></p>
<p>你就是把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 做 inner product,得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>,所以 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 跟<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 的 inner product,那这边我就把这个,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>它背后的这个向量,把它画成比较宽一点代表说它是 transpose</p>
<p>同理 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> 就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,做 inner product, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>  就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>   跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> 做 inner product,这个  <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>  就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 做 inner product</p>
<p>那这个四个步骤的操作,你其实可以把它拼起来,看作是<strong>矩阵跟向量相乘</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409102832459-a5a6c28527030afe27b10b540970b3af.png" width="238" height="189" class="img_ev3q"></p>
<p>这四个动作,你可以看作是我们<strong>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 拼起来,当作是一个矩阵的四个 row</strong></p>
<p>那我们刚才讲过说,我们不只是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>,要对<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 计算 attention,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>也要对 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 计算 attention,操作其实都是一模一样的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409103622596-9fe64050082efb5b09c25901f2d572b3.png" width="806" height="215" class="img_ev3q"></p>
<p>所以这些 <strong>attention 的分数可以看作是两个矩阵的相乘</strong>,一个矩阵它的 row,就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,另外一个矩阵它的 column</p>
<p>我们会在 attention 的分数,<strong>做一下 normalization</strong>,比如说你会做 softmax,你会对这边的每一个 column,每一个 column 做 softmax,让每一个 column 裡面的值相加是 1</p>
<p>之前有讲过说 其实这边做 <strong>softmax不是唯一的选项</strong>,你完全可以选择其他的操作,比如说 ReLU 之类的,那其实得到的结果也不会比较差,通过了 softmax 以后,它得到的值有点不一样了,所以我们用 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>,来表示通过 softmax 以后的结果</p>
<p>我们已经计算出 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>那我们把这个<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>乘上这边的 α 以后,就可以得到 b</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409105513608-20363e5a9ae35dcf0ef0fcf153c7da58.png" width="610" height="221" class="img_ev3q"></p>
<p>你就把<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 拼起来,你<strong>把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>当成是V 这个矩阵的四个 column</strong>,把它拼起来,然后接下来你把 v 乘上,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 的第一个 column 以后,你得到的结果就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></p>
<p>如果你熟悉线性代数的话,你知道说把这个 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 乘上 V,就是把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>的第 一个 column,乘上 V 这一个矩阵,你会得到你 output 矩阵的第一个 column</p>
<p>而把 A 的第一个 column乘上 V 这个矩阵做的事情,其实就是把 V 这个矩阵裡面的每一个 column,<strong>根据第 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 这个矩阵裡面的每一个 column 裡面每一个 element,做 weighted sum</strong>,那就得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></p>
<p>那就是这边的操作,把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 乘上 weight,全部加起来得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>,</p>
<p>如果你是用矩阵操作的角度来看它,就是把<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 的第一个 column 乘上 V,就得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>,然后接下来就是以此类推</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409105935046-ac1d5828ecfbea9ce4f7da76f1d070a3.png" width="609" height="217" class="img_ev3q"></p>
<p>就是以此类推,把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 的第二个 column 乘上 V,就得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 的第三个 column 乘上 V 就得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 的最后一个 column 乘上 V,就得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></p>
<p>所以我们等於就是把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 这个矩阵,乘上 V 这个矩阵,得到 O 这个矩阵,O 这个矩阵裡面的每一个 column,就是 Self-attention 的输出,也就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>,</p>
<p>所以其实整个 Self-attention,我们在讲操作的时候,我们在最开始的时候 跟你讲的时候我们讲说,我们先產生了 q k v,然 后再根据这个 q 去找出相关的位置,然后再对 v 做 weighted sum,其实这一串操作,<strong>就是一连串矩阵的乘法而已</strong></p>
<p>我们再复习一下我们刚才看到的矩阵乘法</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210409110638357-7416fae44aa1bb82cd89b0b3a326a773.png" width="802" height="611" class="img_ev3q"></p>
<ul>
<li>
<p>I 是 Self-attention 的 input,Self-attention 的 input 是一排的vector,这排 vector 拼起来当作矩阵的 column,就是 I</p>
</li>
<li>
<p>这个 input 分别乘上三个矩阵,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span></span></span></span></span></span></span></span> 跟<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span></span></span></span></span></span></span></span>,得到 Q K V</p>
</li>
<li>
<p>这三个矩阵,接下来 Q 乘上 K 的 transpose,得到 A 这个矩阵,A 的矩阵你可能会做一些处理,得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>,那有时候我们会把这个 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>,叫做 ==Attention Matrix==，<strong>生成Q矩阵就是为了得到Attention的score</strong></p>
</li>
<li>
<p>然后接下来你把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 再乘上 V,就得到 O,O 就是 Self-attention 这个 layer 的输出,<strong>生成V是为了计算最后的b，也就是矩阵O</strong></p>
</li>
</ul>
<p>所以 Self-attention 输入是 I,输出是 O,那你会发现说虽然是叫 attention,但是<strong>其实 Self-attention layer 裡面,唯一需要学的参数,就只有 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span></span></span></span></span></span></span></span> 跟<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span></span></span></span></span></span></span></span> 而已,只有<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span></span></span></span></span></span></span></span> 跟<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span></span></span></span></span></span></span></span>是未知的</strong>,是需要透过我们的训练资料把它找出来的</p>
<p>但是其他的操作都没有未知的参数,都是我们人為设定好的,都不需要透过 training data 找出来,那这整个就是 Self-attention 的操作,从 I 到 O 就是做了 Self-attention</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-head-self-attention">Multi-head Self-attention<a href="#multi-head-self-attention" class="hash-link" aria-label="Direct link to Multi-head Self-attention" title="Direct link to Multi-head Self-attention">​</a></h2>
<p>Self-attention 有一个进阶的版本,叫做 ==Multi-head Self-attention==, Multi-head Self-attention,其实今天的使用是非常地广泛的</p>
<p>在作业 4 裡面,助教原来的 code 4 有,Multi-head Self-attention,它的 head 的数目是设成 2,那刚才助教有给你提示说,把 head 的数目改少一点 改成 1,其实就可以过medium baseline</p>
<p>但并不代表所有的任务,都适合用比较少的 head,有一些任务,比如说翻译,比如说语音辨识,其实用比较多的 head,你反而可以得到比较好的结果</p>
<p>至於<strong>需要用多少的 head,这个又是另外一个 hyperparameter</strong>,也是你需要调的</p>
<p>那為什麼我们会需要比较多的 head 呢,你可以想成说相关这件事情</p>
<p>我们在做这个 Self-attention 的时候,我们就是用 q 去找相关的 k,但是**==相关==这件事情有很多种不同的形式**,有很多种不同的定义,所以也许我们不能只有一个 q,我们应该要有多个 q,<strong>不同的 q 负责不同种类的相关性</strong></p>
<p>所以假设你要做 Multi-head Self-attention 的话,你会怎麼操作呢?</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412193656512-6ac90b7c348ca96957dbd04d2dac5994.png" width="816" height="316" class="img_ev3q"></p>
<ul>
<li>先把 a 乘上一个矩阵得到 q</li>
<li>再把 q 乘上另外两个矩阵,分别得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,那这边还有 这边是用两个上标,i 代表的是位置,然后这个 1 跟 2 代表是,这个位置的第几个 q,所以这边有 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0191em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0191em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>,代表说我们有两个 head</li>
</ul>
<p>我们认為这个问题,裡面有两种不同的相关性,是我们需要產生两种不同的 head,来找两种不同的相关性</p>
<p>既然 q 有两个,那 k 也就要有两个,那 v 也就要有两个,从 q 得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,从 k 得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,从 v 得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,那其实就是把 q 把 k 把 v,分别乘上两个矩阵,得到这个不同的 head,就这样子而已,</p>
<p>对另外一个位置,也做一样的事情</p>
<p>只是现在<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>,它在算这个 attention 的分数的时候,它就不要管那个 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 了</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412194346086-4aaf8fce345586236465cb27ecb5675c.png" width="820" height="579" class="img_ev3q"></p>
<ul>
<li>
<p>所以 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> 就跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 算 attention</p>
</li>
<li>
<p><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> 就跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 算 attention,也就是算这个 dot product,然后得到这个 attention 的分数</p>
</li>
<li>
<p>然后今天在做 weighted sum 的时候,也不要管 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 了,看 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 就好,所以你把 attention 的分数乘 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>,把 attention 的分数乘 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>
<p>然后接下来就得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></p>
</li>
</ul>
<p>这边只用了其中一个 head,那你会用另外一个 head,也做一模一样的事情</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412194533453-bee9e4c71b83d0ac207e83bc59578145.png" width="821" height="579" class="img_ev3q"></p>
<p>所以 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 只对 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 做 attention,它们在做 weighted sum 的时候,只对 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 做 weighted sum,然后接下来你就得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>如果你有多个 head,有 8 个 head 有 16 个 head,那也是一样的操作,那这边是用两个 head 来当作例子,来给你看看有两个 head 的时候,是怎麼操作的,现在得到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>然后接下来你可能会把 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 跟 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>,把它接起来,然后再通过一个 transform</p>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAV0AAAClCAYAAAD/Pi53AAAf20lEQVR4nO3deXxU1d348c+9s2aykoUsBAjZSEhYlUVR3EVcW7Dap3WrVWp9fEq1y9Ofv9b216e1re3v181qf7W1tbaP2FpcqhRFFCiKyFL2EBJCyEY2si+z3vv8MWGSCQGSITOZSb7v12t8cWfOvffc65lvzpxz7jmKrus6QgghQkId6wwIIcREIkFXCCFCSIKuEEKEkARdIYQIIeNYZ0AIER4URRnrLISFYI8tkJquEEKEkARdIYQIIWleEEKcYaIN3w9l04rUdIUQIoQk6AohRAhJ0BVCiBCSoCuEECEkQVcIIUJIgq4QQoSQBF0hhAghGacrhBixR9fdMNZZGJGfrtww1lnwkaArhAjItQX3jnUWhuXdIy+MdRb8SNAVQgRmYj20Nmok6AohAiRRNxASdIUQAZGQGxgZvSCEECEkNV0hRICkrhsICbpCiIBMsNkfR40EXSFEgCTqBkLadIUQIoSkpiuECIguNd2ASNAVQgRGYm5AJOgKIQIiNd3ASNAVQgRIgm4gpCNNCBF2dF33vQLdP1xJTVcIEZBgxrWaipNUlddispgonJdHTHz0MPOk43K6qDvRQEJSPAlJccHLZICkpiuECJAetNcbL27gx1/7Fc9+9w90tncOax9N81B24BhPfeVpHv3Ut9i24SPCsQlEarpCiIAEK5z1dPVSfvgEqqqSkBRH6tTJ5zyXrum0nmrntd+v551XtuB0OAEwWUxhGHIl6AohAjb6IU3XdUxmI/d95Q5cDhfxSXEoytnP5XK6ef+Nbbz6/Hpamtpwuzy+zwxGNSh5vFDSvCCECMxZfunrHv3Ml6YPq2WhpuIkdZX1TE5PJjoumoTE+HOmb6pr5tXn13PlLUv5wQv/m2m5U/qzpxGOMVdqukKIwAw1Tre9pYPdW/ejaRqOXidtLR143G4K5uex6Mr55z3mxr9tYeO6raDrOOxOvvaTh1mSetFZ06dOTeGp/36CmPhoNE0jLjF2UA7DL+pK0BVCjJrOti7Wv7SJ46VVfu9PSk4Y1v633rOcjzbtprm+hehYG1NzMs6ZXlVV38gGXeurUYc5aV4QQgTozN/7mdnpfPNXa0ibOtmXymI1kz8ne8j0g1+OXjsOu7cjLCMrjeS0ScPar/81VP7Ci9R0hRABOds4XY+m+32YlJZIZnbGsMb11tc00dnWBcC0nCmYrZZhjwcenE4/Rx7HkgRdIUSAho5oLQ0tNNQ1+7an5WRgi7GeNf1Ah3cf9f27YH7usPY5d37CL+pK0BVCBORs4exEea1f22rRxTP7ap26306KqvgfT9cp+VcZAAajgexZ08dhyJWgOy597ge7SYg2okVAp4IIPkVRSEyw8MS9BaN85KHLV+m+cr9zZxdNR9M8HD9Sza4t+3A6XCSmxLP4mgUkpyX60jbXn6Kxr4Y8xa89d8AZ+9oLFMU/YPfnZ6h23fAiQXccSog2clXxJFye8CtwIvQMqsLequ7RP/AQxUvXdCpK+kcupE9PJTYuhhf+719Z/9+b/NK+99oHPP7L/yAp1Rt4T9W30t3RA0BmdgbWKAtNdadISIrDZDbR1d7N0QMVpGWmkJGVdsa5NY+Gx60N2PaEY8yVoDseaZqOy61J0BUAaKoSlOAz1BjYkzWNtDa3+7aT0ybx8q9f5+DHR1jx6atobmhl1+Z96LpOVXktb730Hnd/eRUATocTj8cbNDvbu3jvtW2sX/seD3/7XnKKsqgsq+EHX/olV39iKQ89cU//9WkamkejdH8F9dWNvvcP7ylj0TUL0Dze2cqGrh2HngTdcehsA2jExBTKclBVXkv7qQ7f9oGPj5CVn8n3/vCfpGam0NrUxomjNTTWepsRjuwpQ9M0VFVlRsE0cmZNp+zAcUr3ltNc38KqB24kpyir70K8V3I6MJ/+99qnX2P/jhJam9robOvCZDYBOh+9u4eKkio0cy+fzvyISy65JGT34VyCFnQfXXdDsA4dFD9duWGssyBERBmqpltVVuO3bY2ycN/X72RyZjI6OtZoK1abxfd5T3cvXR3dxCbEEB1v49GnVlN28DgxcTam52USHWfzncdud6AoCrnFWb73FBWWXLeAwovyMJmNqGr/owe6ruNxezhUt43c3Nxg3IKABLWme23BvcE8/Kh598gLY50FISLQoE4uTefY4RN+791yz3UUzMvxpe3p6sHR4/B9rqoKqqr4Pp+UEseiq+aecQ6PR+P91z5g5rwclt202Pe+okD2rGnnzGX38VJSUlJGfnlBEtzmBfl9Ozb6xqaH48BwEXrBKgeDD9vdbaeytNq3HRVt5bIbF/ml62zvpquzx7cdHRtNVGzUeUNFRUkV5igza77xABabJaJDS5DbdCP51kQ4adQVpwWrHAyK5rXH6uhq7x8lkT83m8SUeL90rY1tvhEKAHGJMShDHGuw7MKpfPHbd2MwGiK+NhHUoBvZt0YIMRLlBytxOly+7cIFeRhN/iHm0K5Sv+25lxYN69iqqo6bmWJk9IIQIiCDO9JODOhEU1SF9OmT/dJ43B72fnjYtx0VbWXWxXlhOf1iMEnzwjgkQ8bEQMEqCwODZW+3nZqKk75ts8VEQnKcX5p/bTtIbV8aRVFYePU8JmcmSdAdTRHe9BK5dC5o+WoxvgSvGPQfuKOlg5pj/UHXYDRgtZl9aRy9Tjas3ewbYzt5ShIrH1x+zqV4xiup6QohAjLw21117KRvHlwAR4+DqvI60mek0dvVy6u/fZtDO4+iKAoJKfF87vE7SZmSPCEjhLTpCiEC1B8yj+wpR1EUomOjsMVG0XyylReeeoV3X9lG/YlG2ls6MZoMFC7I49NrbiVrZiYTtVIW5NELE/OmhoNB80iLCSxYk80NbL5KyUhk/uVFLP/0FWQVZLLz/f0c2lFKZ3s3M+fnkDYthdmXFJA3ewZGk2FCN33JwxHjknSlidC6/s5lXH/nMt/2lbct4crbloxhjsKX1HTHodNPo03gyoQYIHhPpEkBC4R0pAmBgqJ4XzqnV5SVsiuCY1x3pA1cMmTw0iDjnYSN4TEaTeiAvacTp9OB0WTGZotFR/dOgj0OBK8cSAkLxLgep7tl/XZam9qJT4zl8hVLzngkcVyT9oVzUhQVg8FA6cGP2fb+Ok7WVNDZ3kJUdCy5M+ex/Lb7SU6ZgsfjHuusXjhpXggr47Z5ob2lg9/+6M90tXcz95Iilt24ZEzzE0rSjXZuqqqieTy8+tLPefOVZ5meU8Q1N97F9Jxiyo/sYe3zT3Jw7wc89q3nSE6dGvGBV8pCeBm3E97UVTViMpmwxURRvLAQ1WiQgie8FIVX1/6CN15+moVLV/D5L/2QuLgk3B4X2flzsPd08dLzT7Lhjee5a/V3xjq3YWsiD/u6EOOypqvrOln5mXzrmUcB+lYcnWAFJAKqN4rq/Yk/6F00zTNke6o3vRFd17y1z0HXZzAYUVQVvw90cHtcvreMJjN7dmzkzVeeJSV1Knc9+G2io+Nx2Hv7zq6SW7AAg8HEob0f4nE58U5vFeY381yCVBakeSEwYTlOV9f1Qd+b/mWXz7e4nL3HwYGdJd51knSdnu5eklInRfR3JhDhHnMVRaW1pZG66jIMhv5i6Ha5SJqcQfqUHDTN45e+u7OdquMlWKOimZpVgMHQ/+tFUVUqyvbT092B2hfIdU1H1zXyCi/CaDID4HQ6ePv159E8Hq6/9X6SUqbgdNp959F0HRQVg9FAd1cbvb09RNliI7pWJx1p4SUsx+lWllWzc/NeHHYnuqZzqqEFl8vNjf92DUUXzTznvr29dt7880YO7jqCrulERVv5xavfm1h/lSOgUVc1GKivqeCPzz5B66l677orus7ktGnced//YkpmPpreH3SNJhMb3/wD69f9hqlZBTz6reeJiU1A1zzeP8Qa7Nj2FlveWYvb7QJdRzUYWLLsVnIK5oMOqsHIsdJdHD28k7j4JGbPX3bGMt2qotLT2Y7TYSc2LhGTydzXKTkGN2m0hGjlCDE8Ydmd31zfwtb1H1FXWe/3/qrP33TefROS4rj5s9dxcOcRAHKLZ5A4eVJQ8ikC53G7KJp3GXet/g4///6DuN0ubNFxPLDmJ2Tnz8Xt6p88xWAw0njyBFvf/StOpx2ns5eBX3nv8tpwxz3/SduperZvfQOAW+/4Dz75mS9D34xrBoOBw/s+wO12MS17FhmZOd4A7UehsaEKgMTkdIxGswwCOSu5MYEIyzbdi5fNQVUVfrjml76p4KbmZDAlK3VYx2yoafT9HMyfnR1wPiJVBFR0AXC73cwsXkRy6lTqayuYlJRGVu4cXAMCLnhrxf/c9AotzX1TByrqGdeo62CxmImNTwKgoHgJt9zx74CCpmsoiorD3sPxYwcBmDZjFopqQKc/6CqKgtvtpKJsPwD5hQtRDcYhAnNkCdpqPWFfwsJTUBfAGPg46khfHrfmV8PIn52DyWIe1r5Vx+p8++UWzzhvejFWvD/bEyZ5V2qNi0v0a8cFUFUDTQ3VbNn4MjZb7FmPpCoK7W2nKDm4A1U1cPPtX8RisaENGO7lcNjpbG8BICMzF13X/I6hKAod7ac4cuAjFEUlv2gRijJO1ogRYSMsa7oAVeU1aFr/lyJv9oxhTXjc293L8SPen4exCTGkT5t8QfmITHrkTGKuqFis0QBouuZ9DHdAvhVVZcvGv9Dd2cbl197BpvV/ZOAk7afTGkwmDu3bRvXxwyy8dAWz5izF5XJ4/8/3NT94PB7cLu/y37HxiWiD7pHBYGLvzk2caqolJ38+M4sX4XI5I+M+noM3+8EYvhDZ92WsBLemewGvyqMDl3KOYkbhNHS8vcua1v8avF/rqU6qymsBSElPIjUz5bznEmNHURTMFisALqfD74usqgbaW5vY8s5aLr50BdOzZw19DFWlt7eLjX//A2azleWfeBDVYPQLlrquYY2KJiEpFfCOYlDoHwljNJpoOXWSDa//DlU1sOKTq/tGLWhnnE94Xcj3O5SvcBOWNd2u9m5qj/d3oiWmxDM9bwoup4t92w9RdvA4bpeHqdnpLLn2Iqw2iy9tdXkNLqe3DS5rZiZGkyHgfIxURUUFdXV15084QGxsLHPnzh3djERQ04miqL6g66259ufbYDDy4eZX6Whr5vpb76fi6D7ffgObh4xGE9s3v0ZZyS6uufEecvLn43a7/K5f13XMZisFxZew9+NNlOz/kCXLbsMEKKqB9tZG/vzcdzlZXc7y2x5g/uLrcTmdEXEPzycUy/WI4QvLcbptzR3UnWjwbRfMz6X5ZAu/+f6f2L+jxC/tvu2Hefg792Eyey+l8mj/iqQ5s7LQPTqNdc2kZCR5l3EOoscff5yXX355xPtF+s/XC6NgMnn/aNp7u33vqqpKW0sjm956gaJ5l5GVO4ejJbvO3FtR6O3uZOPff090TDzX3HQvuq711VD9x3S7XE4uu+Z2DuzZzOa3X8ISFU1O/nxamuvY8c+/U328hJtWPcTNt/873iaaM48h+h2o3jzWWYhI4TlO92i1r7YK3pVFf/jlpzGZTdy++mZ2bdlHZam3+eGDt3dy5a2XMmdJIQD2Xodvv4baJv72u7fY/1EJX//Zw0TH2i7gas4vMTFxxPtMmhSs4Wzh+uOqn3cYl7G/TVfz9P0B0jEazWzf+jrNjbXc9YXvYjSa8PiNIuhPt2PrG5yoOMRNtz9MRmYOLpdjQBr/81mt0Xzxq79kyztr2b9nM0cPfYzBYCJz+kxuv/vrFBQvxuPxDOjQC+97OFZ+unLDWGchYoXlON3Sfcf8tjf8ZTOX3bCI1d+8C4vVTHbhNH782LO+jpTSfeW+oLtgaTHv/m0rjl4nb/3pXbJnZXH/1+/EFhMV9Hw/88wzPPPMM0E/z/noRE7zgo6C0Wju+7c3zwaDkZZTJ9m0/o8Uzb2MwtlLcbvd9Pb09O+nA4pCZ2cLG17/LYnJGVy94m48Hs85r9vbthvDjau+yIqVD9Hd1Y7NFovBaETzeHC53Iy3QBvpz3aMN2FX0/V4NL9ONICcWdO572t3YLaa0NFJTE3w/urrO3xLU5vvXLMW5vPEbx6j5lgdmdnpZOZkYLaYAs5PpIqUoKugYrH2/wLRde+TY3s+2khTfTWfffD/YDJb0QZNLO5tyzXzwXvrqK4s4d/u/xaJyVNwOnrPe06PR8PjcaAoYLVGe0c1uCN7JrFz0cP/R8+EEnYdaW3NbTSfbPFtW20W7n5sFTHxNt/xWhpb/SYoVwdNcpJdOJXswqkXlA8RGoqiYDJb/LZ7ujvZ/PafmVm0iMLZl+J2OTGa/NOoqoH2libeW/8iGZm5LL7iE35PsQ2H9w/TBBidIMU/rITdkLG6Ew20NLb5jpFTlEXenGy/NE0DgjJAUuqkcTWkZCJRFAWTyerbNppM/GvHO1RXlnDVDXdhNFnO6Gg0ma1YrDY++ucbNNZXsmLlF4mNSzrjwQohwlGQRy+MPKRVldX6PRRRvHAmat9kKKc1VDf57TMpJT4sfks//PDDPPvssyPaZ9KkSbS0tJw/4QhE0tN2mqZjMnuDrgJ0d3Xw9uvPMT1nNrMvuso39Gvg9ZjNVtpbm9m0/gVyCy5iweLluF3jY3hXMATjtjy67oYgHDV4wqnjL+w60soPVvr+rSgKxYv8ZxVz2J1+aaJjo8iamRmy/J1LIMGztbU1CDmJnFq8DhiM3mJoMJnZ01fLffDRn2ONivVNuzjwWqKiY/ng/VdorD/BnZ/7JhZbjPfBCjGkYJWDawvuDdKRR9e7R14Y6yz4CauONKfDRcXhE77t+KQ4ktIm+R3n5IkG33AxgIwZaWTmpodFJ9mTTz7JI488MqJ9YmPPPp/ARKDrOiazd2RJZ1sz77z+HNNz5lC84KozJr45rfFkJUcP72TuxddQOOdyXM6RteWKUTL2X7mIFFZBt+5EA22nOn3bCUmxmCxG33F0XWfHe3txOrzjNRVF4bIbF6KoSlgE3ezsbLKzs8c6G5E1ZEz3znlgMBjp7Gihs6OFzz3yY2y2eFwuu1+609dTc6IUk9nC9beuxmAw4XZL0D2X4BWDCChgYSisRi9UldXgsPf/TIyKsWKyGH3Hqa9q5L112wBvwC1YkMPlNy0a8XkmgkhpXtDQMZktKKoBPG6mTJtJ8UVX43Y7/fKvD/gvwOLLP0Fu4cVnrQ2LfsEqB5FQvsJRWC1MWVla4zcUrLWpne7OXgwmA6fq2/jdk2tpb+lEURTSp0/m7q+swmKzyP/8COZtXrBiNlvRdY0rbriL2LikAU+V9VNVAwaDkdj4ZK6+6T7v0jpCRJiwqek6HS7KD1SiKApWm3eYUEN1M//vsd+QnJ5I+YFKWhrbMFtMFC3M575vfIrk9Am44ORwRNDoBY/bTVpmHo88/jy6rpMxNa9vOkX/dC6nk8VXfJK8oiXYouNIzcjG7YrsycVDRZoXwktwa7oj+NZ73B5SMhKJibexcvUK3C43H6zfxYmjNZysamRKdirzLy/i4qvmULQoH0VRJvhEMedyOuKG//05PfvXjLx5AGiae8gHFnTdQ0JSGonJU9DR/SYnF2NDvn6BCZshY1abhdXf/iyKqmAweJ/ZyJszA5fTha7pGM3GoM8SNl5EUkealz6sJXF0j4bGBHiCbJRJTTe8hNXoBYNJPWM/o7k/i+EwQkEIIS5E2NR0xeiKjMYFEQrBG70gJSwQYdORJkaRTCwhBgtGWZDyFZCwal4Qo0NirhhIarrhRZoXhBABkqAbiLAZMiZGV2SNXhDBFKm/ek7HD0UZX+vUSfPCOBWpXzQx+oLWvBDEAtba3EZrUzuqQSUtMwWrzXrWtKeX7XK73GgeDY9Hw2A0YArTYabSkTZeSdQVQRe8Arbu+bd4888bSU5L5Du//ipTZqQPma6nu5eSPWXs/uc+Svcfo6u9m462TpLTksgrnsENn7oKgr884oiE1dwLYnRIR5oYKNImvOnttlO67xiqqhIdF03q1MlnPdfvf7KWd9dtxWgy8qnVtzBn8Szef+MD3nllMzUVdez98BA3fmNWkHIaGKnpjlNy50XwBaeUqQaF626/gqVdC0mflorB6L8G4kAdrZ0oqsLVt13Gp1bfAkB24XSOHjhGZWk1rc1tlH3UEJR8BkradMejCJrwRgRf0IrBWQ7s14F++p/K8DrEerp6URSFK2+6hPaWTqKiree8gAVLZ5OQGMd1K5f50plMRlKnpPgWO3B0hdfESDJkbByKvLkXRDCFcpxud2cPpfuOATpOu4vuzh40TSMzO4PC+XnnPeYff/YXtm34GKPRQHdXL2u+/wBLly86a/rrbr/ijPzomk5zvXfpLEVRSJkRXquzhN3ClEKIyNV08hR/+vkrnCir8Xv/M4+sHFbQveXu5ezaup+WxlYsVjOZ2RkjzkPZwePUVp4EILcoi7xL0kZ8jGAKuyXYx+I1Ho31PZVX+L1G35lnycrP5CtPPURyWqIvlcFoYObc7GHl0mBQfKuBZ2ZnMDkjaURX6XG7efX367H3OEhOS+ShJ+7BEh1eP+iDPIhtrIvZ2BVHIca7001Yg1+2WBtmq9mXLiUtkak5U86afuCrobaZtuZ2ADKy0rDarMPaT9dB03TWr32Pj9//F5OS4/nS9x9get7Usbo9ZxXUPwEHqjcH8/DiLLyFUJcnAgUAwevQHvq4LY2tNNU1+7YzstKImxRz1vQDeduDvQrm5gxrn9MO7izhpV+9xqTkeB790WpmLcgb0f6hErSg+9OVG4J1aDEMUocXp4U25EJ1RS0uZ//KHkULZ/rS+tZAPMtohkO7SgFQVZX8uTnDzntDTRO//q8XsUVbeeyphyiYn+v9Duh62H0RwquxQwgRQYaOZqV7+2uriqKQVzwDXdM41djKoV2lOOxOElMSKJyfR3SczZe27VQH9dWNAEyekkzKEGsg6rp+RrC29zj4zfdepKO1k8ef/hIF83J8Sz7VnWjg6PZ67DfZsVrP/ihxKEnQHadkyJg4LWjFYIgD67pORckJ33ZyWiKJkxP4x9r3+cv/f4Pujh7fZ3MWF/LYj77gC7yNNc10tncBkJWfidVmpbfLjiXKjKqqOOxOmupOEZsQQ3xirO98f3vuLfbvKOGKmy9B13T2fngIBW+H3Lrfraeh8SQ9j/dI0BXBoygKBnV8zcwkAqcqEIzSMFRbcWNdM6caWn3bmdnp/GPt+7zz1y3MXlxAZ1s3ZQcqANi/o4R//OV9Vj1wIwD2Xjsuh/dBBrfbw/4dh1n32/Xc+9U7yJk1nWMllfzXQz/julWX87mvfxqAQ7uPsv6lTQBs37iLD97e2d+Xoet4PBrpMxMwm/s79saaBN1xqMvu5lhDj9R0BeANuLFxppCcq/pYHW0tHb7tw7uPUl/dyBO/fpSZ83JorG3mic//mJbGNgD+te2AL+hmZKWRPj2VusoG9m0/zPEjVVy7ahlZ+ZkAaG4Nt8tN14Da8t9ffAe3y4OqqrhdnjPyo6oqlmgjJlNorn84JOiOQ79YMwdNAq4YINY2+l/1oWq6VeW1/Z1leGusn12zkvx52ejoxCXGEJsQ4wu6PV29dLR3ERsfTWJqAmt++AAHdhwhblIMucUzSJ822Xcut9uNoihMy5uCjo6maSy/80qWLl+Iahh69Kvm0WhQDmGxWEb9+gMlQXccSk0Mj7YrMd4N6uTSdI4dqvR7b/kdV7Dwqrm+tL09dpx25xDH8X4+LTeDabkZgz7ztt1uf3c3GdNTueLmxYCOqirMu/T8M4htP147gmsKPgm6QoiADK7n2u1OKo5U+bbNFhNXfWKpX7rOtm662rt927aYKKJios7b2VdRUkVzfQtffupB4pLiwm0U2IhI0BVCBGZQp0FtxUk6Wjp927nFWaRmJvula2/poKuzv002NiHa2+l7ng6IzOx01jz5ee9IhwjvrJCgK4QYFccOVeJ09E+jWLggD7PFvwOrdG+5X5tv0cUzh3Vss8V0xrEilQRdIURABnekVR71n1lsSnaaXxpd19m99aBv22Q2UrxkZhAfUw5PEnSFEAEZGCztPXaqj9X5ti1RZhJTE/zSHNxZSlVZf6fWnEtnkT59sgRdIYQYnv5g2dnaRc2xk75tg9GA1Wb2pfG4Pbz98hZcTm/zQ1xiLCsfvOGcS/GMV+G3PrEQIiIMnBy1prKe3m677zOXw0VzQxseTcNhd7LuuQ3s3rwfRVGw2ix8Zs1tZBVMnZATt0pNVwgRoP6QVrK7HEVRMJqMGE0G7L0OXvzJ39g5P4eqslqOl1Sjqipp01L47GOfZN7SWYRnSAw+CbpCiIAMnK/ZYjUxo3Aq19+5jPx52fzzzY85sruc4yVVmK1mFl0zjwXLillwRTG2mKgJPdezBF0hxAX75IM3cOv912Poexx31RdWoOs6mkdDURVUVVoyT5OgK4QIyOBRB6pB8X9PAdWoDpl2IpM/P0IIEUJS0xVCBEhqr4GQoCuECIg0GQRGmheEECKEpKYrhAjIRB72dSEk6AohAiLNC4GRoCuECJAE3UBI0BVCBERCbmAk6AohAiRhNxASdIUQAZE23cDIkDEhhAghqekKIQIjQ8YCIkFXCBEQCbmBkaArhAiQhN1ASNAVQgTkQPXmsc5CRFJ0eZZPCAEoiuL790QLC6G8dhm9IIQQISRBVwghQkiCrhBChJAEXSGECCEJukIIEUIyZEwIcYaBvflidElNVwghQkiCrhBChJA0LwghgIn3QMRYkZquEEKEkARdIYQIIQm6QggRQhJ0hRAihCToCiFECEnQFUKIEJKgK4QQISRBVwghQkiCrhBChJAEXSGECCEJukIIEUISdIUQIoQk6AohRAhJ0BVCiBCSoCuEECEkQVcIIUJIgq4QQoSQBF0hhAih/wFwkaC4GMMsAQAAAABJRU5ErkJggg==" width="349" height="165" class="img_ev3q"></p>
<p>也就是再乘上一个矩阵,然后得到 bi,然后再送到下一层去,那这个就是 Multi-head attention,一个这个 Self-attention 的变形</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="positional-encoding">Positional Encoding<a href="#positional-encoding" class="hash-link" aria-label="Direct link to Positional Encoding" title="Direct link to Positional Encoding">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="no-position-information-in-self-attention">No position information in self-attention<a href="#no-position-information-in-self-attention" class="hash-link" aria-label="Direct link to No position information in self-attention" title="Direct link to No position information in self-attention">​</a></h3>
<p>那讲到目前為止,你会发现说 Self-attention 的这个 layer,它少了一个也许很重要的资讯,这个资讯是<strong>位置的资讯</strong></p>
<p>对一个 Self-attention layer 而言,每一个 input,它是出现在 sequence 的最前面,还是最后面,它是完全没有这个资讯的</p>
<p>对 Self-attention 而言,<strong>位置 1 跟位置 2 跟位置 3 跟位置 4,完全没有任何差别,这四个位置的操作其实是一模一样</strong>,对它来说 q1 到跟 q4 的距离,并没有特别远,1 跟 4 的距离并没有特别远,2 跟 3 的距离也没有特别近</p>
<p>对它来说就是天涯若比邻,所有的位置之间的距离都是一样的,没有任何一个位置距离比较远,也没有任何位置距离比较近,也没有谁在整个 sequence 的最前面,也没有谁在整个 sequence 的最后面</p>
<p>但是这样子设计可能会有一些问题,因為有时候位置的资讯也许很重要,举例来说,我们在做这个 POS tagging,就是词性标记的时候,也许你知道说<strong>动词比较不容易出现在句首</strong>,所以如果我们知道说,某一个词汇它是放在句首的,那它是动词的可能性可能就比较低,这样子的位置的资讯往往  也是有用的</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="each-positon-has-a-unique-positional-vector-ei">Each positon has a unique positional vector <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span><a href="#each-positon-has-a-unique-positional-vector-ei" class="hash-link" aria-label="Direct link to each-positon-has-a-unique-positional-vector-ei" title="Direct link to each-positon-has-a-unique-positional-vector-ei">​</a></h3>
<p>可是在我们到目前為止,讲的 Self-attention 的操作裡面,根本就没有位置的资讯,所以怎麼办呢,所以你做 Self-attention 的时候,如果你觉得位置的资讯是一个重要的事情,那你可以把位置的资讯把它塞进去,怎麼把位置的资讯塞进去呢,这边就要用到一个叫做,==positional encoding== 的技术</p>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,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" width="194" height="193" class="img_ev3q"></p>
<p>你為每一个位置设定一个 vector,叫做 positional vector,这边<strong>用 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span> 来表示,上标 i 代表是位置,每一个不同的位置</strong>,就有不同的 vector,就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 是一个 vector,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 是一个vector,<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">128</span></span></span></span></span></span></span></span></span></span></span></span> 是一个vector,不同的位置都有一个它专属的 e,然后把这个 e 加到 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span> 上面,就结束了</p>
<p>就是告诉你的 Self-attention,位置的资讯,如果它看到说 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span> 好像有被加上 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>,它就知道说现在出现的位置,应该是在 i 这个位置</p>
<p>最早的这个 transformer,就 Attention Is All You Need 那篇 paper 裡面,它用的 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8247em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>长的是这个样子</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412201911959-f569db35625b74f8274d381838c0f5e9.png" width="395" height="551" class="img_ev3q"></p>
<p>这边这个图上面,每一个 column 就代表一个 e,第一个位置就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>,第二个位置就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>,第三个位置就是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>,以此类推</p>
<p>所以它就是把这边这个向量,放在第一个位置,把这个向量加到第二个位置的 a上,把这个向量加到第三个位置的 a 上,以此类推,每一个位置都有一个专属的 e,希望透过给每一个位置不同的 e,你的 model 在处理这个 input 的时候,它可以知道现在的 input,它的位置的资讯是什麼样子</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="hand-crafted-or-learned-from-data">Hand-crafted or Learned from data<a href="#hand-crafted-or-learned-from-data" class="hash-link" aria-label="Direct link to Hand-crafted or Learned from data" title="Direct link to Hand-crafted or Learned from data">​</a></h3>
<p>这样子的 positional vector,它是 handcrafted 的,也就是它是人设的,那人设的这个 vector 有很多问题,就假设我现在在定这个 vector 的时候,只定到 128,那我现在 sequence 的长度,如果是 129 怎麼办呢</p>
<p>不过在最早的那个,Attention Is All You Need paper裡面,没有这个问题,<strong>它 vector 是透过某一个规则所產生的</strong>,透过一个很神奇的sin cos 的 function 所產生的</p>
<p>其实你不一定要这麼產生, <strong>positional encoding仍然是一个尚待研究的问题</strong>,你可以创造自己新的方法,或甚至 positional encoding,是可以根据资料学出来的</p>
<p>那有关 positional encoding,你可以再参考一下文献,这个是一个尚待研究的问题,比如说我这边引用了一篇,这个是去年放在 arxiv 上的论文,所以可以想见这其实都是很新的论文</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412203355853-567ab294c45cbf6e357b25575ef45e0d.png" width="805" height="631" class="img_ev3q"></p>
<p>裡面就是比较了跟提出了,新的 positional encoding</p>
<ul>
<li>比如说这个是最早的 positional encoding,它是用一个神奇的 sin function 所產生的</li>
<li>那如果你的 positional encoding,你把 positional encoding 裡面的数值,当作 network 参数的一部分,直接 learn 出来,看起来是这个样子的,这个图是那个横著看的,它是横著看的,它是每一个 row,代表一个 position,好 所以这个是这个最原始的,用 sin function 產生的,这个是 learn 出来的</li>
<li>它裡面又有神奇的做法,比如说这个,这个是用 RNN 生出来的,positional encording 是用 RNN 出来的,这篇 paper 提出来的叫做 FLOATER,是用个神奇的 network 生出来的,</li>
</ul>
<p>总之你有各式各样不同的方法,来產生 positional encoding,那目前我们还不知道哪一种方法最好,这是一个尚待研究中的问题,所以你不用纠结说,為什麼 Sinusoidal 最好,<strong>你永远可以提出新的做法</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="applications-">Applications …<a href="#applications-" class="hash-link" aria-label="Direct link to Applications …" title="Direct link to Applications …">​</a></h2>
<p>Self-attention 当然是用得很广,我们已经提过很多次 transformer 这个东西</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412204520085-52b86d9517f5ed037c3e2549f0a05339.png" width="529" height="387" class="img_ev3q"></p>
<p>那我们大家也都知道说,在 NLP 的领域有一个东西叫做 BERT,BERT 裡面也用到 Self-attention,所以 Self-attention 在 NLP 上面的应用,是大家都耳熟能详的</p>
<p>但 <strong>Self-attention,不是只能用在 NLP 相关的应用上,它还可以用在很多其他的问题上</strong>,</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="self-attention-for-speech">Self-attention for Speech<a href="#self-attention-for-speech" class="hash-link" aria-label="Direct link to Self-attention for Speech" title="Direct link to Self-attention for Speech">​</a></h3>
<p>比如说在做语音的时候,你也可以用 Self-attention,不过在做语音的时候,你可能会对 Self-attention,做一些小小的改动</p>
<p>因為一般语音的,如果你要把一段声音讯号,表示成一排向量的话,这排<strong>向量可能会非常地长</strong>,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412205436769-0582d8f2f3dcec2f3a7756fe08f63945.png" width="335" height="162" class="img_ev3q"></p>
<p>而每一个向量,其实只代表了 10 millisecond 的长度而已,所以如果今天是 1 秒鐘的声音讯号,它就有 100 个向量了,5 秒鐘的声音讯号,就 500 个向量了,你随便讲一句话,都是上千个向量了</p>
<p>所以一段声音讯号,你要描述它的时候,那个像这个 vector 的 sequence 它的长度是非常可观的,那可观的 sequence,可观的长度,会造成什麼问题呢</p>
<p>你想想看,我们今天在<strong>计算这个 attention matrix 的时候,它的 计算complexity 是长度的平方</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412210111322-3c4c6bd3b52edfd41f1e8d8233a0d330.png" width="345" height="270" class="img_ev3q"></p>
<p>计算这个 attention matrix A′你需要做 L 乘以 L 次的 inner product,那如果这个 L 的值很大的话,它的计算量就很可观,你也 需要很大的这个 memory,才能够把这个矩阵存下来</p>
<p>所以今天如果在做语音辨识的时候,一句话所產生的这个 attention matrix,可能会太大,大到你根本就不容易处理,不容易训练,所以怎麼办呢</p>
<p>在做语音的时候,有一招叫做 ==Truncated Self-attention==</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412210322691-a25c8d409dc66f1279ec1c7ca7e20af2.png" width="370" height="483" class="img_ev3q"></p>
<p>Truncated Self-attention 做的事情就是,我们今天在做 Self-attention 的时候,<strong>不要看一整句话,就我们就只看一个小的范围就好</strong></p>
<p>那至於<strong>这个范围应该要多大,那个是人设定的</strong></p>
<p>那為什麼我们知道说,今天在做语音辨识的时候,也许只需要看一个小的范围就好,那就是<strong>取决於你对这个问题的理解</strong>,也许我们要辨识这个位置有什麼样的<strong>phoneme</strong>,这个位置有什麼样的内容,我们并不需要看整句话,只要看这句话,跟它前后一定范围之内的资讯,其实就可以判断</p>
<p>所以如果在做 Self-attention 的时候,也许没有必要看过一整个句子,也许没有必要让 Self-attention 考虑一整个句子,也许只需要考虑一个小范围就好,这样就可以加快运算的速度，这个是 Truncated Self-attention,</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="self-attention-for-image">Self-attention for Image<a href="#self-attention-for-image" class="hash-link" aria-label="Direct link to Self-attention for Image" title="Direct link to Self-attention for Image">​</a></h3>
<p>那其实 Self-attention ,还可以被用在影像上,Self-attention</p>
<p>那到目前為止,我们在讲 Self-attention 的时候,我们都说 <strong>Self-attention 适用的范围是：输入是一个 vector set 的时候</strong></p>
<p>一张图片啊,我们把它看作是一个很长的向量,那<strong>其实一张图片,我们也可以换一个观 点,把它看作是一个 vector 的 set</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412214143979-35c6408a8b1b63c2da3020f8c1c89897.png" width="554" height="309" class="img_ev3q"></p>
<p>这个是一个解析度 5 乘以 10 的图片,那这一张图片呢,可以看作是一个 tensor,这个 tensor 的大小是 5 乘以 10 乘以 3,3 代表 RGB 这 3 个 channel</p>
<p>你可以把每一个位置的 pixel,看作是一个三维的向量,所以<strong>每一个 pixel,其实就是一个三维的向量</strong>,那<strong>整张图片,其实就是 5 乘以 10 个向量的set</strong></p>
<p>所以我们其实可以换一个角度,影像这个东西,其实也是一个 vector set,它既然也是一个 vector set 的话,你完全可以用 Self-attention 来处理一张图片,那有没有人用 Self-attention 来处理一张图片呢,是有的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412214417887-71543edcad184cecd4990a7370efc5d6.png" width="555" height="426" class="img_ev3q"></p>
<p>那这边就举了两个例子,来给大家参考,那现在把 Self-attention 用在影像处理上,也不算是一个非常石破天惊的事情,</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="self-attention-vs-cnn">Self-attention v.s. CNN<a href="#self-attention-vs-cnn" class="hash-link" aria-label="Direct link to Self-attention v.s. CNN" title="Direct link to Self-attention v.s. CNN">​</a></h4>
<p>我们可以来比较一下,Self-attention 跟 CNN 之间,有什麼样的差异或者是关联性</p>
<p>如果我们今天,是用 Self-attention 来处理一张图片,代表说,假设这个是你要考虑的 pixel,那它產生 query,其他 pixel 產生 key,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412214915856-ff1545f905746655acfe216b4d87e631.png" width="333" height="320" class="img_ev3q"></p>
<p>你今天在做 inner product 的时候,你考虑的不是一个小的receptive field的信息,而是整张影像的资讯</p>
<p>但 是今天在做 CNN 的时候,,会画出一个 receptive field,每一个 filter,每一个 neural,只考虑 receptive field 范围裡面的资讯</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412215451745-0a0fb5158e64d20d84b17a8a72d4af25.png" width="761" height="342" class="img_ev3q"></p>
<ul>
<li>
<p>所以如果我们比较 CNN 跟 Self-attention 的话,<strong>CNN 可以看作是一种简化版的 Self-attention</strong>，因為在做CNN的时候,我们只考虑 receptive field 裡面的资讯,而在做 Self-attention 的时候,我们是考虑整张图片的资讯,所以 CNN,是简化版的 Self-attention</p>
</li>
<li>
<p>或者是你可以反过来说,<strong>Self-attention 是一个复杂化的 CNN</strong></p>
</li>
</ul>
<p>在 CNN 裡面,我们要划定 receptive field,每一个 neural,只考虑 receptive field 裡面的资讯,而 <strong>receptive field 的范围跟大小,是人决定的,</strong></p>
<p>而对 Self-attention 而言,我们用 attention,去找出相关的 pixel,就好像是 <strong>receptive field 是自动被学出的</strong>,network 自己决定说,receptive field 的形状长什麼样子,network 自己决定说,以这个 pixel 為中心,哪些 pixel 是我们真正需要考虑的,那些 pixel 是相关的</p>
<p><strong>所以 receptive field 的范围,不再是人工划定,而是让机器自己学出来</strong></p>
<p>其实你可以读一篇 paper,叫做 On the Relationship,between Self-attention and Convolutional Layers</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412215841085-b57b5f27a46313bcd668e1357a13345e.png" width="837" height="606" class="img_ev3q"></p>
<p>在这篇 paper 裡面,会用数学的方式严谨的告诉你说,其实这个 <strong>CNN就是 Self-attention 的特例,Self-attention 只要设定合适的参数,它可以做到跟 CNN 一模一样的事情</strong></p>
<p>所以 self attention,是更 flexible 的 CNN,而 CNN 是有受限制的 Self-attention,Self-attention 只要透过某些设计,某些限制,它就会变成 CNN</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412220020641-3bba602ff47f5140ab68c6e6b1a65d81.png" width="315" height="175" class="img_ev3q"></p>
<p>那这也不是很旧的 paper,你发现它放到网路上的时间呢,是 19 年的 11 月,所以你知道这些,我们今天上课裡面讲的东西,其实都是很新的资讯</p>
<p>既然Self-attention 比较 flexible,之前有讲说<strong>比较 flexible 的 model,比较需要更多的 data,如果你 data 不够,就有可能 overfitting</strong></p>
<p>而小的 model,而比较有限制的 model,它适合在 data 小的,少的时候,它可能比较不会 overfitting,那如果你这个限制设的好,也会有不错的结果</p>
<p>如果你今天用不同的 data 量,来训练 CNN 跟 Self-attention,你确实可以看到我刚才讲的现象</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210412220707729-d9b7090a7252c2d9a4a7860bd3c1031f.png" width="787" height="570" class="img_ev3q"></p>
<p>那这个实验结果,来自於 An image is worth 16 乘以 16 的 words,这个是 Google 的 paper,它就是把这个 Self-attention,apply 在影像上面</p>
<p>那其实<strong>把一张影像呢,拆成 16 乘以 16 个 patch,它把每一个 patch想像成是一个 word</strong>,因為一般我们这个 Self-attention,比较常用在 NLP 上面,所以他就说,想像每一个 patch 其实就是一个 word,所以他就取了一个很 fancy 的 title,叫做一张图呢,值 16 乘以 16 个文字</p>
<p>横轴是训练的影像的量,那你发现说,对 Google 来说 用的,所谓的资料量比较少,也是你没有办法用的资料量啦这边有 10 个 million 就是,1000 万张图,是资料量比较小的 setting,然后资料量比较大的 setting 呢,有 3 亿张图片,在这个实验裡面呢,比较了 Self-attention 是浅蓝色的这一条线,跟 CNN 是深灰色的这条线</p>
<p>就会发现说,<strong>随著资料量越来越多,那 Self-attention 的结果就越来越好,最终在资料量最多的时候,Self-attention 可以超过 CNN,但在资料量少的时候,CNN 它是可以比 Self-attention,得到更好的结果的</strong></p>
<p>那為什麼会这样,你就可以从 CNN 跟 Self-attention,它们的弹性来加以解释</p>
<ul>
<li>Self-attention 它弹性比较大,所以需要比较多的训练资料,训练资料少的时候,就会 overfitting</li>
<li>而 CNN 它弹性比较小,在训练资料少的时候,结果比较好,但训练资料多的时候,它没有办法从更大量的训练资料得到好处</li>
</ul>
<p>所以这个就是 Self-attention 跟 CNN 的比较，那 Self-attention 跟 CNN,谁比较好呢,<strong>我应该选哪一个呢,事实上你也可以都用</strong>,在我们作业四裡面,如果你要做 strong baseline 的话,就特别给你一个提示,就是用 conformer,裡面就是有用到 Self-attention,也有用到 CNN</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="self-attention-vs-rnn">Self-attention v.s. RNN<a href="#self-attention-vs-rnn" class="hash-link" aria-label="Direct link to Self-attention v.s. RNN" title="Direct link to Self-attention v.s. RNN">​</a></h3>
<p>我们来比较一下,Self-attention 跟 RNN,RNN就是 recurrent neural network,这门课裡面现在就不会讲到 recurrent neural network,因為 recurrent neural network 的角色,很大一部分都可以用 Self-attention 来取代了,</p>
<p>但是 RNN 是什麼呢,假设你想知道的话,那这边很快地三言两语把它带过去,RNN 跟 Self-attention 一样,都是要处理 input 是一个 sequence 的状况</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210413093042847-029188842595d9d661f26293ae77c5cb.png" width="817" height="283" class="img_ev3q"></p>
<p>在 RNN 裡面呢</p>
<ul>
<li>左边是你的 input sequence,你有一个 memory 的 vector</li>
<li>然后你有一个 RNN 的 block,这个 RNN 的 block 呢,它吃 memory 的 vector,吃第一个 input 的 vector</li>
<li>然后 output 一个东西,然后根据这个 output 的东西,我  们通常叫做这个 hidden,这个 hidden 的 layer 的 output</li>
<li>然后通过这个 fully connected network,然后再去做你想要的 prediction</li>
</ul>
<p>接下来当sequence 裡面,第二个 vector 作為 input 的时候,也会把前一个时间点吐出来的东西,当做下一个时间点的输入,再丢进 RNN 裡面,然后再產生新的 vector,再拿去给 fully connected network</p>
<p>然后第三个 vector 进来的时候,你把第三个 vector 跟前一个时间点的输出,一起丢进 RNN,再產生新的输出,然后在第四个时间点</p>
<p>第四个 vector 输入的时候,把第四个 vector 跟前一个时间点,產生出来的输出,再一起做处理,得到新的输出,再通过 fully connected network 的 layer,这个就是 RNN</p>
<p>Recurrent Neural Network跟 Self-attention 做的事情其实也非常像,它们的 <strong>input 都是一个 vector sequence</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210413152809037-c1656acb74dd7830300a1b7c0efc820c.png" width="808" height="564" class="img_ev3q"></p>
<p>Self-attention output 是另外一个 vector sequence,这裡面的每一个 vector,都<strong>考虑了整个 input sequence 以后</strong>,再给 fully connected network 去做处理</p>
<p>那 RNN 呢,它也会 output 另外一群 vector,这另外一排 vector 也会给,fully connected network 做进一步的处理,那 Self-attention 跟 RNN 有什麼不同呢</p>
<p>当然一个非常显而易见的不同,你可能会说,这边的每一个 vector,它都考虑了整个 input 的 sequence,而 RNN 每一个 vector,只考虑了左边已经输入的 vector,它没有考虑右边的 vector,那这是一个很好的观察</p>
<p>但是 <strong>RNN 其实也可以是双向的</strong>,所以如果你 RNN 用双向的 RNN 的话,其实这边的每一个 hidden 的 output,每一个 memory 的 output,其实也可以看作是考虑了整个 input 的 sequence</p>
<p>但是假设我们把 RNN 的 output,跟 Self-attention 的 output 拿来做对比的话,就算你用 bidirectional 的 RNN,还是有一些差别的</p>
<ul>
<li>
<p>对 RNN 来说,假设最右边这个黄色的 vector,要考虑最左边的这个输入,那它必须要把最左边的输入存在 memory 裡面,然后接下来都不能够忘掉,一路带到最右边,才能够在最后一个时间点被考虑</p>
</li>
<li>
<p>但对 Self-attention 来说没有这个问题,它只要这边输出一个 query,这边输出一个 key,只要它们 match 得起来,天涯若比邻,你可以从非常远的 vector,在整个 sequence 上非常远的 vector,轻易地抽取资讯,所以这是 RNN 跟 Self-attention,一个不一样的地方</p>
</li>
</ul>
<p>还有另外一个更主要的不同是,RNN 今天在处理的时候, input 一排 sequence,output 一排 sequence 的时候,<strong>RNN 是没有办法平行化的</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210413153504431-1da7c39b1fc118b04405a2803cbbf3bd.png" width="843" height="632" class="img_ev3q"></p>
<p>RNN 它今天 input 一排是 vector,output 另外一排 vector 的时候,它没有办法一次处理,没有办法平行处理所有的 output</p>
<p>但 Self-attention 有一个优势,是它可以平行处理所有的输出,你今天 input 一排 vector,再 output 这四个 vector 的时候,<strong>这四个 vector 是平行產生的,并不需要等谁先运算完才把其他运算出来</strong>,output 的这个 vector,裡面的 output 这个 vector sequence 裡面,每一个 vector 都是同时產生出来的</p>
<p>所以在运算速度上,Self-attention 会比 RNN 更有效率</p>
<p>那你今天发现说,<strong>很多的应用都往往把 RNN 的架构,逐渐改成 Self-attention 的架构了</strong>,如果你想要更进一步了解,RNN 跟 Self-attention 的关係的话,你可以看下面这篇文章,Transformers are RNNs,裡面会告诉你说,Self-attention 你加上了什麼东西以后,其实它就变成了 RNN,发现说这也不是很旧的 paper,这个是去年的六月放到 arXiv 上</p>
<p>所以  今天讲的都是一些很新的研究成果,那 RNN 的部分呢,我们这门课就不会提到,假设你对 RNN 有兴趣的话,以下是这一门课之前的上课录影,那 RNN 的部分,因為这一次不会讲到,所以特别有做了英文的版本,RNN 呢 是中文英文版本,都同时有放在 YouTube 上面</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210413153721866-a9c519ee1648c16f453a095f87dd233a.png" width="703" height="499" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="self-attention-for-graph">Self-attention for Graph<a href="#self-attention-for-graph" class="hash-link" aria-label="Direct link to Self-attention for Graph" title="Direct link to Self-attention for Graph">​</a></h3>
<p>Graph 也可以看作是一堆 vector,那如果是一堆 vector,就可以用 Self-attention 来处理,所以 Self-attention 也可以用在 Graph 上面,但是当我们把 Self-attention,用在Graph 上面的时候,有什麼样特别的地方呢,、</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210413154403199-88be715f0b0cf5dcf99817bf16910c85.png" width="776" height="479" class="img_ev3q"></p>
<p>在 Graph 上面,每一个 node 可以表示成一个向量,但<strong>不只有 node 的资讯,还有 edge 的资讯</strong>,我们知道哪些 node 之间是有相连的,也就是哪些 node 是有关联的</p>
<p>我们知道哪些向量间是有关联,那之前我们在做 Self-attention 的时候,所谓的关联性是 network 自己找出来的,但是现在既然有了 Graph 的资讯,<strong>有了 edge 的资讯,那关联性也许就不需要透过机器自动找出来,这个图上面的 edge 已经暗示了我们,node 跟 node 之间的关联性</strong></p>
<p>所以今天当你把 Self-attention,用在 Graph 上面的时候,你有一个选择是你在做这个,Attention Matrix 计算的时候,你可以<strong>只计算有 edge 相连的 node 就好</strong></p>
<p>举例来说在这个图上,node 1 跟 node 8 有相连,那我们只需要计算 node 1 跟 node 8,这两个向量之间的 attention 的分数,那 1 跟 6 相连,所以只有 1 跟 6 之间,需要计算 attention 的分数,1 跟 5 有相连,所以只有 1 跟 5 需要计算 attention 的分数,2 跟 3 有相连,所以只有 2 跟 3 需要计算 attention 的分数,以此类推</p>
<p>那如果两个 node 之间没有相连,那其实很有可能就暗示我们,这两个 node 之间没有关係,<strong>既然没有关係,我们就不需要再去计算它的 attention score,直接把它设為 0 就好了</strong></p>
<p>因為这个 <strong>Graph 往往是人為根据某些 domain knowledge 建出来的</strong>,那 domain knowledge 告诉我们说,这两个向量彼此之间没有关联,我们就没有必要再用机器去学习这件事情</p>
<p>其实当我们把 Self-attention,按照我们这边讲的这种限制,用在 Graph 上面的时候,其实就是一种 Graph Neural Network,也就是一种 GNN</p>
<p>那我知道 GNN,现在也是一个很 fancy 的题目,那我不会说 Self-attention 就要囊括了,所有 GNN 的各种变形了,但把 Self-attention 用在 Graph 上面,是某一种类型的 Graph Neural Network,那这边呢,一样我们也没有办法细讲了,GNN 这边坑也是很深啊,这边水是很深,那就放一下助教之前上课的连结</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210413154823956-30e32cef83fbe2420a45cb4589e7f2f1.png" width="701" height="416" class="img_ev3q"></p>
<p>大概花了快三个小时,在讲 Graph Neural Network,而且其实还没有讲完,就告诉你说这个 Graph Neural Network,也是有非常深的技术,这边水也是很深,那这不是我们今天这一堂课可以讲的内容,好</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="more">More<a href="#more" class="hash-link" aria-label="Direct link to More" title="Direct link to More">​</a></h2>
<p>其实Self-attention 有非常非常多的变形,你可以看一篇 paper 叫做,Long Range Arena,裡面比较了各种不同的 Self-attention 的变形</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210413155347467-67b192e8abe3aa020340ea0cd8b5a939.png" width="792" height="623" class="img_ev3q"></p>
<p>因為 Self-attention 它最大的问题就是,<strong>它的运算量非常地大</strong>,所以怎麼样减少 Self-attention 的运算量,是一个未来的重点,可以看到这边有,各种各式各样 Self-attention 的变形</p>
<p>Self-attention 最早是,用在 Transformer 上面,所以很多人讲 Transformer 的时候,其实它指的就是这个 Self-attention,有人说广义的 Transformer,指的就是 Self-attention,那所以后来各式各样的,Self-attention 的变形都这样做,都叫做是什麼 former,比如说 Linformer Performer Reformer 等等,所以 Self-attention 的变形,现在都叫做 xxformer</p>
<p>那可以看到，往右代表它运算的速度,所以有很多各式各样新的 xxformer,它们的速度会比原来的 Transformer 快,但是快的速度带来的就是 performance 变差</p>
<p>这个纵轴代表是 performance,所以它们往往比原来的 Transformer,performance 差一点,但是速度会比较快</p>
<p>那到底什麼样的 Self-attention,才能够真的又快又好,这仍然是一个尚待研究的问题,如果你对 Self-attention,想要进一步研究的话,你还可以看一下,Efficient Transformers: A Survey 这篇 paper,裡面会跟你介绍,各式各样 Self-attention 的变形。</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#矩阵的角度" class="table-of-contents__link toc-highlight">矩阵的角度</a></li><li><a href="#multi-head-self-attention" class="table-of-contents__link toc-highlight">Multi-head Self-attention</a></li><li><a href="#positional-encoding" class="table-of-contents__link toc-highlight">Positional Encoding</a><ul><li><a href="#no-position-information-in-self-attention" class="table-of-contents__link toc-highlight">No position information in self-attention</a></li><li><a href="#each-positon-has-a-unique-positional-vector-ei" class="table-of-contents__link toc-highlight">Each positon has a unique positional vector e^i</a></li><li><a href="#hand-crafted-or-learned-from-data" class="table-of-contents__link toc-highlight">Hand-crafted or Learned from data</a></li></ul></li><li><a href="#applications-" class="table-of-contents__link toc-highlight">Applications …</a><ul><li><a href="#self-attention-for-speech" class="table-of-contents__link toc-highlight">Self-attention for Speech</a></li><li><a href="#self-attention-for-image" class="table-of-contents__link toc-highlight">Self-attention for Image</a></li><li><a href="#self-attention-vs-rnn" class="table-of-contents__link toc-highlight">Self-attention v.s. RNN</a></li><li><a href="#self-attention-for-graph" class="table-of-contents__link toc-highlight">Self-attention for Graph</a></li></ul></li><li><a href="#more" class="table-of-contents__link toc-highlight">More</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>