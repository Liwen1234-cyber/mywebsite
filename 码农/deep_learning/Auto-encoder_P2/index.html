<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-码农/deep_learning/Auto-encoder_P2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Auto-Encoder P2 | Coisini</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://doc.minddiy.top/码农/deep_learning/Auto-encoder_P2/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Auto-Encoder P2 | Coisini"><meta data-rh="true" name="description" content="Feature Disentangle"><meta data-rh="true" property="og:description" content="Feature Disentangle"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://doc.minddiy.top/码农/deep_learning/Auto-encoder_P2/"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/Auto-encoder_P2/" hreflang="en"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/Auto-encoder_P2/" hreflang="x-default"><meta name="google-site-verification" content="1FUPX6Qo4y3ecU623ShEurhgnjhSTjK49rRMhEDlzFA">
<link rel="stylesheet" href="/katex/katex.min.css">
<script src="/js/matomo.js" async defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.79037026.css">
<script src="/assets/js/runtime~main.468f2b27.js" defer="defer"></script>
<script src="/assets/js/main.4763ab3e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Coisini</b></a></div><div class="navbar__items navbar__items--right"><a href="https://minddiy.top" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Main site<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Auto-Encoder P2</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="feature-disentangle">Feature Disentangle<a href="#feature-disentangle" class="hash-link" aria-label="Direct link to Feature Disentangle" title="Direct link to Feature Disentangle">​</a></h2>
<p>接下来啊,除了 Auto-Encoder,可以用来做当 strime 的任务以外,我还想跟大家分享一下,Auto-Encoder 其他有意思的应用： ==Feature  Disentanglement==</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210714145952267-15d12317e4d63c168a756037494617b3.png" width="519" height="349" class="img_ev3q"></p>
<p>Disentangle 的意思就是,把一堆本来纠缠在一起的东西把它解开</p>
<p>那为什么会有 Disentangle 这个议题呢,我们来想想看,Auto-Encoder 它在做的事情是什么</p>
<p>Auto-Encoder 在做的事情是</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210714150218260-a2830c185e458ea05aebf9d4572e47e6.png" width="511" height="415" class="img_ev3q"></p>
<ul>
<li>如果是图片的话,就是把一张图片变成一个 Code,再把 Code 呢 变回图片,既然这个 Code 可以变回图片,代表说这个 Code 裡面啊,有很多的资讯,包含图片裡面所有的资讯,举例来说,图片裡面有什么样的东西啊,图片的色泽纹理啊等等</li>
<li>Auto-Encoder 这个概念也不是只能用在影像上,如果用在语音上,你可以把一段声音丢到 Encoder 裡面,变成向量 再丢回 Decoder,变回原来的声音,代表这个向量包含了,语音裡面所有重要的资讯,包括这句话的内容是什么,就是 Encoder 的资讯,还有这句话是谁说的,就是 Speaker 语者的资讯</li>
<li>那如果今天是一篇文章,丢到 Encoder 裡面变成向量,这个向量通过 Decoder 会变回原来的文章,那这个向量裡面有什么,它可能包含文章裡面,文句的句法的资讯,也包含了语意的资讯,但是这些资讯是全部纠缠在一个向量裡面,我们并不知道一个向量的哪些维,代表了哪些资讯</li>
</ul>
<p>举例来说,如果我们今天把一段声音讯号丢进 Encoder,它会给我们一个向量,但是这个向量裡面,哪些维度代表了这句话的内容,哪些维度代表这句话的语者,也就是谁说的,我们没有这样的资讯</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210717133633109-e90eb30e29ea3f5d298b900090d79543.png" width="507" height="321" class="img_ev3q"></p>
<p>而 Feature Disentangle 想要做到的事情就是,我们有没有可能想办法,在 Train 一个 Auto-Encoder 的时候,同时有办法知道,这个 Representation,或又叫做 Embedding,或又叫做 Code,我们这个 <strong>Embedding 的哪些维度代表了哪些资讯</strong>呢</p>
<p>我们有没有可能做到说 Encoder 输出一个,举例来说 100 维的向量,我们知道说<strong>前 50 维就代表了这句话的内容</strong>,<strong>后 50 维就代表了这句话说话人的特徵</strong>呢,那这样子的技术就叫做 Feature Disentangle</p>
<p>我们就是主要就想告诉大家说,Feature Disentangle 是有办法做的,那至于实际上怎么做,我在这边就列几篇论文,给有兴趣的同学参考,如果你没有兴趣的话,就知道说这件事情是可行的,我们有可能知道 Auto-Encoder 裡面,每一个 Dimension 代表了什么样的资讯</p>
<p>这边举一个语音上的应用,这个应用叫做 Voice Conversion,Voice Conversion 的中文叫做语者转换,所以也许你没有听过语者转换这个词彙,但是你一定看过它的应用,它就是柯南的领结变身器</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210717140504984-001b44e418375f8b820c73fff18ffae9.png" width="515" height="383" class="img_ev3q"></p>
<p>这个在二十年前,阿笠博士就已经做得很成功了啦</p>
<p>那只是过去,阿笠博士在做这个 Voice Conversion 的时候啊,我们需要成对的声音讯号,也就是假设你要把 A 的声音转成 B 的声音,你必须把 A 跟 B 都找来,叫他唸一模一样的句子</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210717140541591-41714d7e81fa46f01ca7cd651ed4261b.png" width="553" height="408" class="img_ev3q"></p>
<p>就 A 说好 How are you,B 也说好 How are you,A 说 Good morning,B 也说 Good morning,他们两个各说一样的句子,说个 1000 句,接下来呢,就结束了,就是 <strong>Supervised Learning 的问题</strong>啊,你有成对的资料,Train 一个 Supervised   的 Model,把 A 的声音丢进去,输出就变成 B 的声音,就结束了</p>
<p>但是如果 A 跟 B 都需要唸一模一样的句子,念个 500 1000 句,显然是不切实际的,举例来说,假设我想要把我的声音转成新垣结衣的声音,我得把新垣结衣找来,更退一万步说,假设我真的把新垣结衣找来,她也不会说中文啊,所以她没有办法跟我唸一模一样的句子</p>
<p>而今天有了 Feature Disentangle 的技术以后,也许我们期待机器可以做到,<strong>就给它 A 的声音 给它 B 的声音,A 跟 B 不需要唸同样的句子,甚至不需要讲同样的语言,机器也有可能学会把 A 的声音转成 B 的声音</strong></p>
<p>那实际上是怎么做的呢,假设我们收集到一大堆人类的声音讯号,然后拿这堆声音讯号呢,去 Train 一个 Auto-Encoder,同时我们又做了 Feature Disentangle 的技术,所以我们<strong>知道在 Encoder 的输出裡面,哪些维度代表了语音的内容,哪些维度代表了语者的特徵</strong></p>
<p>接下来,我们就可以<strong>把两句话,声音跟内容的部分互换</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210717155052660-a52845d7e90c4509f1033e82a3a040db.png" width="552" height="297" class="img_ev3q"></p>
<p>举例来说,这边是我的声音,我说 How are you,丢进 Encoder 以后,那你就可以抽出,你就知道说这个 Encoder 裡面,<strong>某些维度代表 How are you 的内容,某些维度代表我的声音</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210717211046635-da969f632d2ef3450e41253372ec4c69.png" width="557" height="295" class="img_ev3q"></p>
<p>今天你把这个你老婆的声音丢进 Encoder,它就知道某一些维度,代表你老婆说的话的内容,某一些维度,代表你老婆声音的特徵,接下来我们只要<strong>把我说话的内容的部分取出来</strong>,<strong>把你老婆说话的声音特徵的部分取出来,把它拼起来</strong>,丢到 Decoder   裡面,就可以用<strong>你老婆的声音,讲我说的话的内容</strong></p>
<p>这件事情真的有可能办到吗,以下是真正的例子,听起来像是这个样子,Do you want to study a PhD,这个是我的声音，那把我的声音丢到 Encoder 裡面以后呢,你可以想像说在 Encoder 裡面,我们知道哪些维度代表了念博班这件事,哪些维度代表了我的声音</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210717212919024-76fa7a3dd59d3df2475d14de06e73723.png" width="550" height="323" class="img_ev3q"></p>
<p>那为了简化起见,它输出 100 维的向量,前 50 维代表内容,后 50 维代表说话人的特徵,好 接下来这句话是你老婆说的,仕事忙しいのがな,不知道 不太确定在说什么,就是日文啊</p>
<p>接下来呢,就把我的声音的前 50 维,代表内容的部分取出来,把你老婆的,把你老婆的声音丢进 Encoder 以后,后 50 维的部分抽出来,拼起来,一样是一个 100 维的向量,丢到 Decoder 裡面,看看输出来的声音,是不是就是你老婆叫你念博班的声音,听起来像是这个样子,Do you want to study a PhD</p>
<p>那其实反过来也可以啦,就是换成把日文的部分拿出来,把我的声音的特徵拿出来,一样串成一个 100 维的向量,丢到 Decoder 裡面,它听起来就会变成这样,仕事忙しいのがな,我也不知道自己在说什么就是了</p>
<p>所以确实用 Feature Disentangle,你有机会做到 Voice Conversion,那其实在影像上,在 NLP 上,也都可以有类似的应用,所以可以想想看,Feature Disentangle 可以做什么样的事情</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="discrete-latent-representation">Discrete Latent Representation<a href="#discrete-latent-representation" class="hash-link" aria-label="Direct link to Discrete Latent Representation" title="Direct link to Discrete Latent Representation">​</a></h2>
<p>下一个要跟大家讲的应用,叫做 Discrete Latent Representation</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210718145909442-56a899b2570a2dfa8720a5a50f03c3a8.png" width="514" height="349" class="img_ev3q"></p>
<p>到目前为止我们都假设这个 Embedding,它就是一个向量,这样就是一串数字,它是 Real Numbers,那它可不可以是别的东西呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210718150617371-5d5ab3ee342ded5c0957753f132c3527.png" width="533" height="417" class="img_ev3q"></p>
<ul>
<li>举例来说,它可不可以是 Binary,Binary 的好处也许是说,每一个维度,它就代表了某种特徵的有或者是没有,举例来说,输入的这张图片,如果是女生,可能第一维就是 1,男生第一维就是 0,如果有戴眼镜,就是第三维 1,没有戴眼镜 就是第三维是 0,也许我们把这个向量,这个 Embedding 变成 Binary,变成只有 0 跟 1 的数字,可以让我们再解释 Encoder 输出的时候,更为容易</li>
<li>甚至有没有可能这个向量,强迫它一定要是 One-Hot 呢,也就只有一维是 1,其他就是 0,如果我们强迫它是 One-Hot,也就是每一个东西图片丢进去,你只可以有,你的 Embedding 裡面只可以有一维是 1,其他都是 0 的话,那可以做到什么样的效果呢,也许可以做到 unSupervised 的分类,举例来说,假设你有一大堆的,假设你想要做那个手写数字辨识,你有 0 到 9 的图片,你把 0 到 9 的图片统统收集起来,Train 一个这样子的 Auto-Encoder,然后强迫中间的 Latent Representation,强迫中间的这个 Code 啊,一定要是 One-Hot Vector,那你这个 Code 正好设个 10 维,也许每一个 One-Hot 的 Code,所以这 10 维,就有 10 种可能的 One-Hot 的 Code,也许每一种 One-Hot 的 Code,正好就对应到一个数字也说不定,所以今天如果用 One-Hot 的 Vector,来当做你的 Embedding 的话,也许就可以做到完全在没有,完全没有Llabel Data 的情况下,让机器自动学会分类</li>
</ul>
<p>其实还有其他,在这种啊 Discrete 的 Representation 的这个,技术裡面啊,其中最知名的就是 ==VQVAE==,Vector Quantized Variational Auto-Encoder,</p>
<p>VQVAE 啊,是这样子运作的,就是你输入一张图片,Encoder 呢 输出一个向量,这个向量它是一般的向量,它是 Continuous 的,但接下来你有一个 ==Codebook==</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803095530316-939d3a07ab89ab962bf9e11adf6f5cde.png" width="876" height="430" class="img_ev3q"></p>
<p>所谓 Codebook 的意思就是,你有一排向量,这排向量也是 Learn 出来的,你把 Encoder 的输出,去跟这排向量都去算个<strong>相似度</strong>,那你发现这件事情啊,其实跟 Self-attention 有点像,上面这个 Vector 就是 Query,下面这些 Vector 就是 Key,那接下来呢就看这些 Vector 裡面,谁的<strong>相似度最大</strong>,那你把相似度最大的那个 Vector 拿出来</p>
<p>这边就是那个,这个 Key 跟那个 Value,是等于是共用同一个 Vector</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803100016342-ab0c05958c2a93a068574a0bdf3e23ee.png" width="655" height="394" class="img_ev3q"></p>
<p>如果你把这整个 Process,用 Self-attention 来比喻的话,那就等于是 Key 跟 Value 是共同的 Vector,然后把这个 Vector 呢,丢到 Decoder 裡面,然后要它输出一张图片,然后接下来 Training 的时候,就是要让输入跟输出越接近越好</p>
<p>这一个 Decoder,这个 Encoder,这一个 Codebook,都是一起从资料裡面被学出来的,这样做的好处就是你就可以,你就有 Discrete 的这个 Latent Representation,也就是说这边 Decoder 的输入,一定是这边这个 Codebook,裡面的向量的其中一个,假设你 Codebook 裡面有 32 个向量,那你 Decoder 的输入,就只有 32 种可能,你等于就是让你的这个 Embedding,它是离散的,它没有无穷无尽的可能,它只有 32 种可能而已</p>
<p>那其实像这样子的技术啊,如果你拿它 把它用在语音上,你就是一段声音讯号输进来, 通过 Encoder 以后产生一个向量,接下来呢,你去计算这个相似度,把最像的那个向量拿出来丢给 Decoder,再输出一样的声音讯号,这个时候你会发现说你的 Codebook 啊,可能可以学到最基本的发音部位</p>
<p>举例来说 你的,这个最基本的发音单位啊,又叫做 ==Phonetic==,那如果你不知道 Phonetic 是什么的话,你就把它想成是 KK 音标,那你就会发现说,这个 Codebook 裡面每一个 Vector,它就对应到某一个发音,就对应到 KK 音标裡面的某一个符号,这个是 VQVAE</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="text-as-representation">Text as Representation<a href="#text-as-representation" class="hash-link" aria-label="Direct link to Text as Representation" title="Direct link to Text as Representation">​</a></h3>
<p>那其实还有更多疯狂的想法,Representation 一定要是向量吗,能不能是别的东西</p>
<p>举例来说,它能不能是一段文字,是可以的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803101112898-577e922e44b0c2e80a8fa6294f369f34.png" width="870" height="279" class="img_ev3q"></p>
<p>假设我们现在要做文字的 Auto-Encoder,那文字的 Auto-Encoder 的概念,跟语音的影像的没有什么不同,就是你有一个 Encoder,一篇文章丢进去,也许产生一个什么东西 一个向量,把这个向量丢到 Decoder,再让它还原原来的文章,但我们现在可不可以不要用向量,来当做 Embedding,我们可不可以说我们的 Embedding,就是一串文字呢</p>
<p>如果把 Embedding 变成一串文字,有什么好处呢,也许这串文字就是文章的摘要,因为你想想看,把一篇文章丢到 Encoder 的裡面,它输出一串文字,而这串文字,可以通过 Decoder 还原回原来的文章,那代表说这段文字,是这篇文章的精华,也就是这篇文章最关键的内容,也就是这篇文章的摘要</p>
<p>不过啊 这边的 Encoder,显然需要是一个 <strong>Seq2seq 的 Model</strong>,比如说 Transformer,因为我们这边输入是文章嘛,这边输出是一串文字嘛,这个 Decoder 输入是一串文字,输出是文章嘛,所以都是输入一串东西,输出一串东西,输入一串文字 输出一串文字,所以 Encoder 跟 Decoder,显然都必须要是一个 Seq2seq 的 Model</p>
<p>它不是一个普通的 Auto-Encoder,它是一个 seq2seq2seq 的 Auto-Encoder,它把长的 Sequence 转成短的 Sequence,再把短的 Sequence 还原回长的 Sequence,而这个 Auto-Encoder 大家训练的时候,不需要标注的资料,因为训练 Auto-Encoder,只需要收集大量的文章,收集大量没有标注的资料,在这边就是大量的文章就可以了</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803101235002-d2a67026efa01e98b88185c984e19795.png" width="871" height="530" class="img_ev3q"></p>
<p>如果你真的可以训练出这个模型,如果这串文字真的可以代表摘要的话,你就是让机器自动学会做摘要这件事,让机器自动学会做,unSupervised 的 Summarization</p>
<p>但是真的有这么容易吗,实际上这样 <strong>Train 起来以后发现是行不通的</strong>,为什么,因为这两个 Encoder 跟 Decoder 之间,会发明自己的暗号啊,所以它会产生一段文字,那这段文字是你看不懂的,你看不懂的文字,这 Decoder 可以看得懂,它还原得了原来的文章,但是人看不懂,所以它根本就不是一段摘要,所以怎么办呢</p>
<p><strong>再用 GAN 的概念,加上一个 Discriminator</strong></p>
<p>Discriminator 看过人写的句子,所以它知道人写的句子长什么样子,但这些句子,不需要是这些文章的摘要性,另外一堆句子,所以它知道人写的句子长什么样子</p>
<p>然后呢,这个 Encoder 要想办法去骗过 Discriminator,Encoder 要想办法产生一段句子,这段句子不只可以透过 Decoder,还原回原来的文章,还要是 Discriminator 觉得像是人写的句子,期待通过这个方法,就可以强迫 Encoder,不只产生一段密码可以给 Decoder 去破解,而是产生一段人看得懂的摘要</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803102018852-46b85eb12d6197a85bbff3226376032f.png" width="878" height="648" class="img_ev3q"></p>
<p>那你可能会问说,这个 Network 要怎么 Train 啊,这个 Output 是一串文字哦,那这个文字要怎么接给 Discriminator,跟这个 Decoder 呢,告诉你,看到你没办法 Train 的问题,就用 RL 硬做,这样这边就是 RL 硬做就结束了这样子</p>
<p>你可能会觉得这个概念有点像 <strong>CycleGAN</strong>,没错 你可以想这根本就是 CycleGAN,就是这是一个 Generator,这是另外一个 Generator,这是 Discriminator,你要输入跟输出越接近越好,其实这根本就是 CycleGAN,我们只是从 Auto-Encoder 的角度,来看待 CycleGAN 这个想法而已,</p>
<p>那实际上做的结果是怎么样呢,以下是真正 Network 输出的结果啦,你给它读一篇文章,然后它就用 Auto-Encoder 的方法,拿 300 万篇文章做训练以后,然后看看给它一篇新的文章,它可不可以是,那个 Encoder 的输出的句子,是不是就是人可以看得懂的摘要</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803102224453-5a2f8be3488b35284302652bc979a5b4.png" width="594" height="353" class="img_ev3q"></p>
<p>举例来说,给 Encoder 看这篇文章,它的输出是,澳大利亚加强体育竞赛之外的药品检查,看起来还可以,那这边有一个特别强的啦,就是这篇文章是,中华民国奥林匹克委员会,今天接到一九九二年冬季奥运会邀请函,丢给 Encoder 之后,它的输出是奥委会接获冬季奥运会邀请函,它知道把奥林匹克委员会,自己就缩写成奥委会,这个不知道怎么回事,它自己就学到了这件事情</p>
<p>当然很多时候,它也是会犯错的,我特别喜欢举这种极其犯错的例子</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803102507802-04edbccbf8d3fed72e02247a5b09efd2.png" width="601" height="356" class="img_ev3q"></p>
<p>举例来说,你给它读这篇文章,印度尼西亚苏门答腊岛近日来连降暴雨,机器产生的摘要是什么呢</p>
<p>Encoder 的输出是,印尼门洪水泛滥,印尼门是什么东西呢,大概就是印度尼西亚苏门的缩写啦,可能人类写的句子裡面,常常出现罗生门 (风二门),等等什么门,所以机器觉得,Encoder 觉得印度尼西亚苏门,应该可以缩写成印尼门</p>
<p>那有时候它也会产生莫名其妙的句子啊,比如说把这篇文章给机器读了以后,Encoder 的输出是,合肥领导干部下基层做搞迎来送往规定一律简,不知道在说些什么,总之是个句子 不知道在说些什么,好 所以这个例子只是想要告诉你说,我们确实有可能,拿一段文字来当做 Embedding</p>
<p>其实还有更狂的,我还看过有拿 Tree Structure,当做 Embedding,就一段文字把它变成 Tree Structure,再用 Tree Structure 还原一段文字,</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803102648978-d2b80d7d4b8d0b6be3a8029aeb64f64d.png" width="651" height="421" class="img_ev3q"></p>
<p>好 我把 Reference 列在这边给大家参考</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="more-applications">More Applications<a href="#more-applications" class="hash-link" aria-label="Direct link to More Applications" title="Direct link to More Applications">​</a></h2>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803103329473-ff6238c7230ab2c9c27f153ebc1e1de4.png" width="606" height="350" class="img_ev3q"></p>
<p>接下来啊,还有 Auto-Encoder 更多的应用,Auto-Encoder 还可以拿来做些什么事情呢,举例来说,我们刚才用的都是 Encoder,那其实 Decoder 也有作用</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="generator">Generator<a href="#generator" class="hash-link" aria-label="Direct link to Generator" title="Direct link to Generator">​</a></h3>
<p>你把 Decoder 拿出来,这不就是一个 <strong>Generator</strong> 吗,我们说 Generator,不是就是要吃一个向量,产生一个东西,比如说一张图片吗,而 Decoder 不正好是吃一个向量,产生一张图片吗,所以 Decoder,你可以把它<strong>当做一个 Generator 来使用</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803104340119-fa4bba324cebc6e899b12879539d9359.png" width="622" height="381" class="img_ev3q"></p>
<p>你可以从一个已知的 Distribution,比如说 Gaussian Distribution,Sample 一个向量,丢给 Decoder,看看它能不能够输出一张图</p>
<p>事实上在我们之前,在讲这个 Generative Model 的时候,其实有提到说除了 GAN 以外,还有另外两种 Generative 的 Model,其中一个就叫做 VAE,Variarional 的 Auto-Encoder,你看它名字裡面的 Auto-Encoder,显然是跟 Auto-Encoder 非常有关係的,它其实就是把 Auto-Encoder 的 Decoder 拿出来,当做 Generator 来用,那实际上它还有做一些其他的事情啊,至于它实际上做了什么其他的事情,就留给大家自己研究</p>
<p>所以 Auto-Encoder Train 完以后,也顺便得到了一个 Decoder</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="compression">Compression<a href="#compression" class="hash-link" aria-label="Direct link to Compression" title="Direct link to Compression">​</a></h3>
<p>Auto-Encoder 可以拿来<strong>做压缩</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803104611861-8c441a779d5534ef791d71d0985ccf3d.png" width="587" height="365" class="img_ev3q"></p>
<p>我们今天知道说你在做图片,我们图片如果太大的话,也会有一些压缩的方法,比如说 JPEG 的压缩,而 Auto-Encoder 也可以拿来做压缩,你完全可以把 Encoder 的输出,当做是一个压缩的结果,因为一张图片,是一个非常高维的向量,而一般我们 Encoder 的输出,是一个非常低维的向量,你完全可以把那个向量,看作是一个压缩的结果</p>
<p>所以你的 Encoder 做的事情,就是压缩,你的 Decoder 做的事情,就是解压缩</p>
<p>只是这个压缩啊,它是那种 lossy 的压缩,所谓 <strong>lossy 的压缩就是它会失真</strong>,因为在 Train Auto-Encoder 的时候,你没有办法 Train 到说,输入的图片跟输出的图片,100% 完全一模一样啦,它还是会有一些差距的</p>
<p>所以这样子的 Auto-Encoder 的压缩技术,你拿这样子的技术来做压缩,那你的图片是会失真的,就跟 JPEG 图片会失真一样,用这个 Auto-Encoder 来做压缩,你的图片也是会失真的</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="anomaly-detection">Anomaly Detection<a href="#anomaly-detection" class="hash-link" aria-label="Direct link to Anomaly Detection" title="Direct link to Anomaly Detection">​</a></h3>
<p>那接下来,就是我们在作业裡面要使用的技术,在作业裡面我们会拿 Auto-Encoder,来做 Anomaly 的 Detection,那我在规划作业的时候,其实就是想要 Auto-Encoder 出一个作业,那 Auto-Encoder 的技术很多,那最后我决定做 Anomaly 的 Detection，因为这个是你在非常多的场合,都有机会应用到的一个技术</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803110021868-97d87e3d46daa3acac7ed9bef54972ab.png" width="649" height="358" class="img_ev3q"></p>
<p>Anomaly 的 Detection ,假设你有一堆的训练资料,这边用 X1 到 XN 来表示我们的训练资料,而 Anomaly Detection,它的中文通常翻译成异常检测</p>
<p>异常检测要做的事情就是,<strong>来了一笔新的资料,它到底跟我们之前在训练资料裡面看过的资料,相不相似</strong>呢,也就是说你需要找出,你需要有一个异常检测的系统,这个异常检测的系统,是透过大量你已经看过的资料训练出来的</p>
<ul>
<li>给它一笔新的资料,如果这笔新的资料,看起来像是训练资料裡面的 Data,就说它是正常的</li>
<li>如果看起来不像是训练资料裡面的 Data,就说它是异常的</li>
</ul>
<p>那其实 Anomaly,Anomaly 这个词啊,有很多不同的其他的称呼,比如说有时候你会叫它 Outlier,有时候你会叫它 Novelty,有时候你会叫它 Exceptions,但其实指的都是同样的事情,你就是要看某一笔新的资料,它跟之前看过的资料到底相不相似,但是所谓的<strong>相似这件事啊,其实并没有非常明确的定义</strong>,它是见仁见智的,会根据你的应用情境而有所不同</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803133222034-dfbdece5ea4511677cbf8766ce1b7b46.png" width="673" height="421" class="img_ev3q"></p>
<p>举例来说</p>
<ul>
<li>假设现在你的训练资料这个都是雷丘,那这个皮卡丘就算是异常的东西</li>
<li>但是假设你的训练资料裡面,你所有的动物都是皮卡丘,那雷丘就是异常的东西,所以我们并不会说,某一个东西它一定就是 Normal,一定就是 Anomaly,我们不会说某个东西它一定是正常或异常,它<strong>是正常或异常,取决于你的训练资料长什么样子</strong></li>
<li>或者是说假设你的训练资料裡面,通通都是宝可梦,那雷丘跟皮卡丘通通都算是正常的,而可能数码宝贝,亚古兽知道吗,这应该是亚古兽 对不对,亚古兽算是异常的</li>
</ul>
<p>那个这个异常检测有什么样的应用呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803133604585-cf3da11db804829983411569900d266c.png" width="635" height="324" class="img_ev3q"></p>
<ul>
<li>举例来说,它可以来做诈欺侦测,假设你的训练资料裡面,有一大堆信用卡的交易纪录,那我们可以想像说,多数信用卡的交易都是正常的,那你拿这些正常的信用卡训练的交易纪录,来训练一个异常检测的模型,那有一笔新的交易纪录进来,你就可以让机器帮你判断说,这笔纪录算是正常的 还是异常的,所以这种异常检测的技术,可以拿来做诈欺侦测</li>
<li>或者是它可以拿来做网路的这个侵入侦测,举例来说,你 有很多连线的纪录资料,那你相信多数人连到你的网站的时候,他的行为都是正常的,多数人都是好人,你收集到一大堆正常的连线的纪录,那接下来有一笔新的连线进来,你可以根据过去正常的连线,训练出一个异常检测的模型,看看新的连线,它是正常的连线 还是异常的连线,它是有攻击性的 还是正常的连线,或者是它在医学上也可能有应用,你收集到一大堆正常细胞的资料,拿来训练一个异常检测的模型,那也许看到一个新的细胞,它可以知道这个细胞有没有突变,也许有突变,它就是一个癌细胞等等</li>
</ul>
<p>那讲到这边有人可能会想说,Anomaly Detection 异常检测的问题,我们能不能够把它当做<strong>二元分类</strong>的问题来看啊</p>
<p><img decoding="async" loading="lazy" alt="image-20210803133706511" src="data:image/png;base64,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" width="302" height="125" class="img_ev3q"></p>
<p>你说你要做诈欺侦测,你就收集一大堆正常的信用卡纪录,一堆诈欺的信用卡纪录,训练一个 Binary 的 Classifier,就结束啦,就这样子不是吗,</p>
<p>比较<strong>难点就是你要收资料</strong></p>
<p>这种异常检测的问题它的难点,正在就在收资料上面,通常你<strong>比较有办法收集到正常的资料,你比较不容易收集到异常的资料</strong>,你可能有一大堆信用卡交易的纪录,但是多数信用卡交易的纪录可能都是正常的,异常的资料相较于正常的资料,可能非常地少,甚至有一些异常的资料混在正常的裡面,你也不太可,你可能也完全没有办法侦测出来,所以在这一种异常检测的问题裡面</p>
<p>我们往往假设,我们有一大堆正常的资料,但我们几乎没有异常的资料,所以它<strong>不是一个一般的分类的问题</strong>,这种分类的问题又叫做 ==One Class 的分类问题==,就是我们只有一个类别的资料,那你怎么训练一个模型,因为你想你要训练一个分类器,你得有两个类别的资料,你才能训练分类器啊,如果只有一个类别的资料,那我们可以训练什么东西,这个时候就是 Auto-Encoder,可以派得上用场的时候了</p>
<p>举例来说,假设我们现在想要做一个系统,这个系统是要侦测说一张图片</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803134026264-b15f0c2c61a60328f86c4a3242410f4f.png" width="736" height="527" class="img_ev3q"></p>
<p>举例来说,它是不是真人的人脸,那你可以找到一大堆图片,它都是真正的人脸,那我们就拿这些真人的人脸,来训练一个 Auto-Encoder</p>
<p>这个是你老婆的照片,那你可以拿它来训练一个 Auto-Encoder,那你训练完这个 Auto-Encoder 以后,在测试的时候,如果进来的也是你老婆的照片,那因为在训练的时候有看过这样的照片,所以它可以顺利地被还原回来</p>
<p>你可 以计算这一张照片通过 Encoder,再通过 Decoder 以后,它的变化有多大,你可以去<strong>计算这个输入的照片,跟这个输出的照片,它们的差异有多大</strong>,如果差异很小,你的 Decoder 可以顺利地还原原来的照片,代表这样类型的照片,是在训练的时候有看过的,不过反过来说,假设有一张照片是训练的时候没有看过的</p>
<p>举例来说这根本不是人的照</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210803134138489-f8ff5acc37e373f35e542e7b2b68a2b4.png" width="738" height="449" class="img_ev3q"></p>
<p>她是那个凉宫春日,但是她不是真人,她是一个动画的人物,她是二次元的人物,一个二次元人物的照片,输入 Encoder 再输出 Decoder 以后,</p>
<p>因为这是没有看过的东西,这是训练的时候没有看过的照片,那你的 Decoder,就很难把它还原回来,如果你计算输入跟输出的差异,发现差异非常地大,那就代表说,现在输入给 Encoder 的这张照片,可能是一个异常的状况,可能是训练的时候没有看过的状况,所以你就可以看 reconstruction 的 loss,这个 reconstruction 的好坏,来决定说你现在在测试的时候,看到这张照片,是不是训练的时候有看过同类型的照片,</p>
<p>这个就是我们,好 那这个就是我们在作业裡面,要大家做的事情啦</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="more-about-anomaly-detection">More about Anomaly Detection<a href="#more-about-anomaly-detection" class="hash-link" aria-label="Direct link to More about Anomaly Detection" title="Direct link to More about Anomaly Detection">​</a></h3>
<p>那这个异常检测啊,其实也是另外一门学问,那我们课堂上就没有时间讲了,异常检测不是只能用 Auto-Encoder 这个技术,Auto-Encoder 这个技术,只是众多可能方法裡面的其中一个,我们拿它来当做 Auto-Encoder 的作业,因为我相信,你未来有很多的机会用得上异常检测这个技术,那  实际上有关异常检测更完整的介绍,我们把过去上课的录影放在这边,给大家参考,</p>
<p>•Part 1: <a href="https://youtu.be/gDp2LXGnVLQ" target="_blank" rel="noopener noreferrer">https://youtu.be/gDp2LXGnVLQ</a></p>
<p>•Part 2: <a href="https://youtu.be/cYrNjLxkoXs" target="_blank" rel="noopener noreferrer">https://youtu.be/cYrNjLxkoXs</a></p>
<p>•Part 3: <a href="https://youtu.be/ueDlm2FkCnw" target="_blank" rel="noopener noreferrer">https://youtu.be/ueDlm2FkCnw</a></p>
<p>•Part 4: <a href="https://youtu.be/XwkHOUPbc0Q" target="_blank" rel="noopener noreferrer">https://youtu.be/XwkHOUPbc0Q</a></p>
<p>•Part 5: <a href="https://youtu.be/Fh1xFBktRLQ" target="_blank" rel="noopener noreferrer">https://youtu.be/Fh1xFBktRLQ</a></p>
<p>•Part 6: <a href="https://youtu.be/LmFWzmn2rFY" target="_blank" rel="noopener noreferrer">https://youtu.be/LmFWzmn2rFY</a></p>
<p>•Part 7: <a href="https://youtu.be/6W8FqUGYyDo" target="_blank" rel="noopener noreferrer">https://youtu.be/6W8FqUGYyDo</a></p>
<p>那以上就是有关 Auto-Encoder 的部分</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#feature-disentangle" class="table-of-contents__link toc-highlight">Feature Disentangle</a></li><li><a href="#discrete-latent-representation" class="table-of-contents__link toc-highlight">Discrete Latent Representation</a><ul><li><a href="#text-as-representation" class="table-of-contents__link toc-highlight">Text as Representation</a></li></ul></li><li><a href="#more-applications" class="table-of-contents__link toc-highlight">More Applications</a><ul><li><a href="#generator" class="table-of-contents__link toc-highlight">Generator</a></li><li><a href="#compression" class="table-of-contents__link toc-highlight">Compression</a></li><li><a href="#anomaly-detection" class="table-of-contents__link toc-highlight">Anomaly Detection</a></li><li><a href="#more-about-anomaly-detection" class="table-of-contents__link toc-highlight">More about Anomaly Detection</a></li></ul></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>