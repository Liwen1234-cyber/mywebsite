<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-码农/deep_learning/Domain Adaptation" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">27 Domain Adaptation | Coisini</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://doc.minddiy.top/码农/deep_learning/Domain Adaptation/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="27 Domain Adaptation | Coisini"><meta data-rh="true" name="description" content="到目前為止,我们已经训练了很多,Machine Learning 的 Model,所以对大家来说,训练一个 Classifier 完全不是一个问题"><meta data-rh="true" property="og:description" content="到目前為止,我们已经训练了很多,Machine Learning 的 Model,所以对大家来说,训练一个 Classifier 完全不是一个问题"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://doc.minddiy.top/码农/deep_learning/Domain Adaptation/"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/Domain Adaptation/" hreflang="en"><link data-rh="true" rel="alternate" href="https://doc.minddiy.top/码农/deep_learning/Domain Adaptation/" hreflang="x-default"><meta name="google-site-verification" content="1FUPX6Qo4y3ecU623ShEurhgnjhSTjK49rRMhEDlzFA">
<link rel="stylesheet" href="/katex/katex.min.css">
<script src="/js/matomo.js" async defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.79037026.css">
<script src="/assets/js/runtime~main.468f2b27.js" defer="defer"></script>
<script src="/assets/js/main.4763ab3e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Chialisp Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Coisini</b></a></div><div class="navbar__items navbar__items--right"><a href="https://minddiy.top" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Main site<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>27 Domain Adaptation</h1></header>
<p>到目前為止,我们已经训练了很多,Machine Learning 的 Model,所以对大家来说,训练一个 Classifier 完全不是一个问题</p>
<p>所以假设要你训练一个数字的 Classifier,你只要有给你训练资料,你训练好一个模型,然后 Apply 在 用在测试资料上就结束了,那像数字辨识这麼简单的问题,你在 Benchmark Corpus,在MNIST Benchmark Corpus 上,随便做一做,可能都会做到 99.5% 的正确率</p>
<p>但是假设今天<strong>测试资料,跟训练资料的分布不一样</strong>,怎麼办呢</p>
<p>我们举一个简单的例子,假设<strong>训练</strong>的时候,你的<strong>数字是黑白</strong>的,但<strong>测试</strong>的时候,你的<strong>数字是彩色</strong>的,会发生什麼样的事情呢</p>
<p>你可能会觉得说,一边是黑白的 一边是,虽然一边是黑白的 一边是彩色的,但是对 Model 来说,数字的形状是一样的,它能够在黑白的图片上认出数字来,在彩色的图片上,会不会应该也可以认出数字来呢</p>
<p>但实际上不是,如果你今天在这样子黑白的数字上面,训练一个模型,直接用到彩色的数字上,你得到的正确率会非常地低,会低到只有 57%,不能算是一个及格的分数</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210910220128165-c15449f69bd7f02ed21734ed6c6baf27.png" width="648" height="484" class="img_ev3q"></p>
<p>所以我们今天知道说,一旦训练资料跟测试资料,它中间有一些差异,它们中间的分布是不一样的,你在训练资料上训练出来的模型,在测试资料上面可能就会坏掉,那这种问题 叫做 ==Domain Shift==,也就是当你的训练资料跟测试资料,它的分布有些不同的时候,这种状况叫做 Domain Shift</p>
<p>在多数的这种作业裡面,或者是 Benchmark Corpus 裡面,我们都假设无视 Domain Shift 这个问题,我们的训练资料跟测试资料,往往有著一样的分布,那这样都会给大家一个错误的印象就是,哇 这个今天的什麼人工智慧,真的是很厉害,都超越人类啦,在很多任务上面都有极高的正确率,但是实际上用在真实的应用上,当你的训练资料跟测试资料的中间,有一点差异的时候,机器能不能够做得好,就是一个未知数了</p>
<p>那我们今天就是要来讲说,假设训练资料跟测试资料,有一点差异的时候,有没有什麼方法可以让我们,能够做 得比什麼都不做结果还要好</p>
<p>那今天就是要讲 ==Domain Adaptation== 的技术,那 Domain Adaptation 的技术,也可以看做是 ==Transfer Learning== 的一种</p>
<p>Transfer Learning 就是,你在 A 任务上学到的技能,可以被用在 B 任务上,那对於 Domain Adaptation 来说,你的训练资料是一个 Domain,你的测试资料是另外一个 Domain,你在训练资料上面,某一个 Domain 上学到的资讯,你要把它用到另外一个 Domain,用到测试资料上面,所以你是把一个 Domain 学到的知识,用在另外一个 Domain 上,所以它可以看做是,Transfer Learning 的其中一个环节,那在过去上课的录影裡面,有完整的讲了 Transfer Learning 相关的技术,那因為今天时间有限,我们就只 Focus 在,Domain Adaptation 的部分就好,如果你有兴趣的话,你可以再看一下过去上课的录影</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="domain-shift">Domain Shift<a href="#domain-shift" class="hash-link" aria-label="Direct link to Domain Shift" title="Direct link to Domain Shift">​</a></h2>
<p>Domain Shift,其实有很<strong>多种不同的类型</strong>,我们刚才看到的,只是 Domain Shift 的其中一种可能,是模型输入的资料的分布有变化的状况,那输入分布有变化是一种可能性</p>
<p>其实还有另外一种可能性是,<strong>输出的分布也可能有变化</strong>,举例来说 在你的训练资料上面,可能每一个数字它出现的机率都是一样的,但是在测试资料上面,可能每一个输出的机率是不一样的,有可能某一个数字它输出的机率特别大,有没有可能有这种事情发生呢,这也是有可能的</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210910220642626-5d812b2eb6f05db3ca1a9dc627972f8c.png" width="614" height="281" class="img_ev3q"></p>
<p>那这也是一种 Domain Shift,还有一种更罕 比较罕见,但也不是完全不可能发生的状况是,<strong>输入跟输出虽然分布可能是一样的,但它们之间的关係变了</strong></p>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,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" width="521" height="102" class="img_ev3q"></p>
<p>也许在你的训练资料裡面,这种东西叫做 0,但是在你的测试资料裡面,这种东西叫做 1,这也不是不可能的,也是有可能发生这种状况嘛,也是有可能发生说,输入跟输出它们的关係不一样,在训练跟测试资料不一样的状况,那这又是另外一种 Domain Shift</p>
<p>那我们今天呢 只专注在,输入资料不同的 Domain Shift 的上面,好 那在等一下的课程裡面,这个<strong>测试的资料</strong>,我们说它来自 ==Target Domain== <strong>训练的资料</strong>,我们说它来自 ==Source Domain==,所以 <strong>Source Domain 是我们的训练资料,Target Domain 是我们的测试资料</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="domain-adaptation">Domain Adaptation<a href="#domain-adaptation" class="hash-link" aria-label="Direct link to Domain Adaptation" title="Direct link to Domain Adaptation">​</a></h2>
<p>在 Domain Adaptation 裡面,我们的这个情境是这个样子的,我们有一堆训练资料,那这边我们就直接拿手写数字辨识,来当作我们的例子啦</p>
<p>我们有一堆训练资料,那这些资料来自 Source Domain,而且这些训练资料是有标註的,我们知道每张图片对应的数字是什麼,但是我们希望再用这些资料,训练出一个模型,这个模型可以用在不一样的 Domain 上</p>
<p><img decoding="async" loading="lazy" src="C:%5CUsers%5C10131%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210910222206884.png" alt="image-20210910222206884" class="img_ev3q"></p>
<p>那要<strong>把这个模型用在不一样的 Domain 上</strong>,在训练的时候,我们就必须要对另外一个 Domain,也就是现在测试资料所在的 Target Domain,有一些了解,那随著了解的程度不同,我们就有不同的 Domain Adaptation 的方法</p>
<ul>
<li>
<p>那了解最多的是,假设我们在 Target Domain 上,我们有<strong>一点资料</strong>,而且这些资料居然还有 Label, 那这是一种情况</p>
</li>
<li>
<p>但还有另外一种更好的状况是,也许你根本在 Target Domain 上,就有<strong>一大堆的资料</strong>,那些资料也都有 Label,那你其实就不需要做 Domain Adaptation,你直接拿 Target Domain 的资料来训练就好了</p>
</li>
</ul>
<p>所以如果你在 Target Domain 上,已经有一大堆的资料,而且它们还有标註,那你不需要做 Domain Adaptation</p>
<p>那要做 Domain Adaptation 的情境可能是,你有 <strong>Target Domain 的资料 也有标註,但是量非常地少</strong>,那在这种状况下怎麼办呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210910222347878-c636036e6479d797166a366ceb2f7657.png" width="663" height="288" class="img_ev3q"></p>
<p>那这种状况还算是在 Domain Adaptation 裡面,比较容易处理的状况,如果你今天遇到的是,有标註资料 只是资料量很少的情况下,你可以用这些有标註的资料,来<strong>微调你在 Source Domain 上训练出来的模型</strong>,那这边所谓的微调,就跟你在做 BERT 的时候的行為很像,就是你已经有一个在 Source Domain 上,训练好的 Model,那你拿 Target Domain 的 Data,只稍微跑个两 三个（Epoch）就足够了</p>
<p>那在这一种情境下,你需要注意的问题就是,因為你的 Target Domain 的资料量非常少,所以你要小心 不要 Overfit,也就是说 你**不要在 Target Domain 上的资料上,跑太多的  Iteration,**那如果你跑太多的 Iteration,可能会 Overfit 到 Target 的这些少量的资料上,然后呢 你在你真正的 Testing Set 上就做不好,这是有可能的</p>
<p>那為了避免 Overfitting 的情况,过去就有很多的 Solution,比如说 把 Learning Rate 调小一点,举例来说 你要让（fine tune）前,跟（fine tune）后的模型的参数,不要差很多,或者是让（fine tune）前,跟（fine tune）后的模型,它的输入跟输出的关係,不要差很多 等等,那有很多不同的方法,那这边呢 我们就  不细讲</p>
<p>那今天主要想要跟大家分享的情境,也是我们作业要处理的情境是,我们在 <strong>Targe Domain 上有大量的资料</strong>,但是这些资料是<strong>没有标註</strong>的,你的 Targe Domain 是有顏色的数字,你也蒐集到了一大堆有顏色的数字的图片,但是没有人标註说,每一张图片裡面的数字是什麼</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911162419412-32ec4ac27781039b722d681a26ac207e.png" width="684" height="284" class="img_ev3q"></p>
<p>那我们在作业裡面要处理的就是,遇到这种状况的时候,到底应该要怎麼解呢,好 到底应该要怎麼解呢</p>
<p>那像这种情境,其实是蛮符合你在真实的系统上,有可能会发生的情境,举例来说 你在实验室裡面训练了一个模型,你想要把它用在真实的场域裡面,你就把你的模型上线,那确实有一些人来用,但是你发现你得到的 Feedback 很差,大家都嫌弃你的系统正确率很低,那怎麼办,但是你这个时候,你也许就可以用 Domain Adaptation 的技术,那因為你的系统已经上线,也真的有人使用,所以你可以蒐集到一大堆的资料,只是这些资料它们是没有标註的</p>
<p>那现在要问的问题是,<strong>怎麼用这些没有标註的资料,来帮助我们在 Source Domain 上,训练出一个模型</strong>,它可以用在 Targe Domain 上呢</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-idea">Basic Idea<a href="#basic-idea" class="hash-link" aria-label="Direct link to Basic Idea" title="Direct link to Basic Idea">​</a></h3>
<p>那这边最 Basic 的想法是这个样子的,这边基本的概念是这个样子,我们想要<strong>找一个 Feature Extractor</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911162648850-0e7a6128a31e2844ca9721a2a2ad683b.png" width="699" height="454" class="img_ev3q"></p>
<p>这个 Feature Extractor,它其实也是一个 Network,这个 Network 呢 吃一张  图片作為输入,它吐出一个 vector,吐出一个 Feature,虽然 Source Domain 跟 Target Domain,它们的 Image 表面上看起来不一样,但是 Feature Extractor,会<strong>把它们不一样的部分拿掉,只抽取出它们共同的部分</strong></p>
<p>所以虽然从图片上看起来,这两组图片一个有顏色 一个没有顏色,它本来就很不一样,但是我们期待说,这个 Feature Extractor 可以学到,就无视顏色这件事情,把顏色的资讯滤掉,那今天不管是来自 Source Domain 的图片,还是来自 Target Domain 的图片,只要通过这个 Feature Extractor 以后,它得到的 Feature 看起来是没有差异的,它们看起来有一样的分布,那这样你就可以用这些 Feature,训练一个模型,在 Source Domain 上训练一个模型,直接用在 Target Domain 上,那接下来的问题就是,怎麼找出这样一个 Feature Extractor</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="domain-adversarial-training">Domain Adversarial Training<a href="#domain-adversarial-training" class="hash-link" aria-label="Direct link to Domain Adversarial Training" title="Direct link to Domain Adversarial Training">​</a></h3>
<p>怎麼找出这样的一个 Feature Extractor 呢,那其实我们可以<strong>把一个一般的 Classifier,就分成 Feature Extractor,跟 Label Predictor 两个部分</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911163352331-14888546b731f73060d74bfadc457ba2.png" width="713" height="189" class="img_ev3q"></p>
<p>我们知道一个 Image 的 Classifier,就是输入一张 Image Output,就是分类的结果,那假设这个 Image 的 Classifier 有 10 层,那我们就说,前 5 层算是 Feature Extractor,后 5 层算是 Label Predictor,因為前 5 层,你一个 Image 通过前 5 层,它输出就是一个 vector 嘛,那如果你上 CNN 的话,它输出其实是 Feature Map 啦,但 Feature Map 拉直,也可以看做是一个 vector 嘛,那这个 vector,再丢到 Label Predictor 的后面 5 层,它会產生 Class,那所以我们可以把前 5 层,看做是 Feature Extractor</p>
<p>那你可能会问说,那為什麼是前 5 层呢,為什麼不是前 4 层 前 3 层 前 2 层 前 1 层呢,可以是前 4 前 3 前 2 前 1,这个是你自己决定的,<strong>一个 Classifier 裡面,哪些部分算 Feature Extractor,哪些部分算是 Label Predictor,这个是你自己决定的,那这个也算是一个 Hyper Paramete</strong>r 啦,就跟 Network 架构要调一下一样,要调一样</p>
<p>那如果你今天呢,用 Domain Adaptation 的方法,那这边等一下要用的方法叫,==Domain Adversarial Training==</p>
<p>用 Domain Adversarial Training,你要把 Classifier 裡面的哪个部分 哪几层,当做 Feature Extractor,这个也要问你自己,那这个也是你自己要决定的</p>
<p>那我们现在要怎麼来训练这个,Feature Extractor 跟 Label Predictor 呢,今天对於 Source Domain 上的资料,Source Domain 上的资料是有标註的,我们就期待把 Source Domain 的资料丢进去,那就去跟训练一个一般的分类器一样,它通过 Feature Extractor,再通过 Label Predictor,可以產生正确的答案</p>
<p>但不一样的地方是,Target Domain 的这些资料,我们有一堆 Target Domain 的资料,但这些资料是没有任何的标註的,这些资料是没有任何的标註的,所以我们<strong>不能说把这些资料丢进去以后,期待 Label Predictor 会 Output 什麼数字</strong>,因為我们根本不知道 Label Predictor,要 Output 什麼数字才是对的</p>
<p>但是这些资料可以怎麼被使用呢,这些资料的使用方式就是,我们把这些图片丢到这个 Image,丢进这个 Image Classifier,然后我们把,Feature Extractor 的 Output 拿出来看,拿出来看以后,我们希望 <strong>Source Domain 的图片,丢进去的 Feature,跟 Target Domain 的图片丢进去的 Feature,它们看起来要分不出差异</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911163602009-c622cfe1e8751eb0c63c79d6e55e3826.png" width="718" height="411" class="img_ev3q"></p>
<p>就是这个 Source Domain 的图片,我们用它的 Feature,我们用蓝色的点来表示,Target Domain 的图片,它的 Feature 我们用红色的点来表示,我们要这些蓝色的点跟这些红色的点,分不出差异,那怎麼让蓝色的点跟红色的点,分不出差异呢,那这个就要藉由,Domain Adversarial Training 的技术</p>
<p>那我们现在要做的事情就是,训练一个 Domain 的 Classifier,这个 Domain 的 Classifier,它就是一个<strong>二元的分类器</strong>,它吃这个 vector 当作输入,它要做的事情就是判断说,<strong>这个 vector 是来自於 Source Domain,还是来自於 Target Domain</strong></p>
<p>而 Feature Extractor 它学习的目标,就是要去想办法骗过这个 Domain Classifier,那听到骗过这件事情</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911164939478-77379b018a6b38370553843779f99759.png" width="895" height="483" class="img_ev3q"></p>
<p>是不是让你脑中就浮现了,Gan 这个东西,是不是就浮现了,Generative Adversaria Network 这个东西呢,没错 Domain Adversarial Training,就非常像是 Gan,你可以把 Feature Extractor,想成是 Generator,把 Domain Classifier,想成是 Discriminator,那其实 Domain Adversarial Training,最早的 Paper,我记得是发表在 2015 年的 ICML 上面,比那个 Gan 还要稍微晚一点点啦,不过它们几乎可以说是同时期的作品,在 Domain Adversarial Training 那篇 Paper 裡面,是有引用到 Gan 那篇 Paper,但那时候 Gan 那篇 Paper,还没有上<a href="https://neurips.cc/" target="_blank" rel="noopener noreferrer">NeurIPS</a>,所以它只说,欸 有一篇 有另外一篇 Paper,它提了一个叫 Gan 的想法,然后它是 Technical report 放在网路上的,还跟我的想法有点像,所以它们算是一个同时期的作品</p>
<p>但是讲到这边,这个 Domain Adversarial Training,跟 Gan 还是有一点不一样,那在这个游戏裡面,对 <strong>Generator 好像优势太大了</strong>,那对 Generator 来说,它要骗过 Discriminator,完全不需要花什麼力气,有一个非常无脑的做法,就是你的 Feature Extractor,也就是你的 <strong>Generator,不管看到什麼输入,永远都输出 0 就好了</strong></p>
<p>看到什麼输入我都输出一个 Zero vector,那对 Domain Classifier 来说,它完全不知道 Input 的 Image 是什麼,它永远都看到 Zero vector,它就完全无法分辨这个 vector,来自於哪一个 Domain,但是这显然不是我们要的状况,如果 Feature Extractor 只会输出 Zero vector,那这样子等於根本就什麼事都没有做是一样的</p>
<p>那这件事情会发生吗,其实<strong>这件事情是不会发生的</strong>,為什麼,因為 <strong>Label Predictor 也需要这个 Feature</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911165220437-311a3bed30cfdfdafc5877dda098d9ec.png" width="887" height="538" class="img_ev3q"></p>
<p>Label Predictor 它也需要这个 Feature,让它可以去判断,输入的图片属於哪一个类别,所以假设 Generator 它就直接放一个大绝说,今天不管输入什麼样的 Image,我输出都是 Zero vector,那对於 Label Predictor 来说,它就没有办法判断是哪一张图片,那在这个情况下,因為 Feature Extractor,它还是需要產生这个 vector,让 Label Predictor 可以產生正确的图片,所以 Feature Extractor 它就不能放大绝,它就不能看到什麼东西,永远都输出 Zero vector</p>
<p>那这边呢,我们用符号再稍微把我们刚才讲过的事情,再重新说 说得更清楚一点</p>
<ul>
<li>假设 Label Predictor 的参数,我们就叫它 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></li>
<li>Domain Classifier 的参数 叫做 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></li>
<li>然后 Feature Extractor 的参数 叫做 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911172941695-619eda50de23a6d8058f141f6915609d.png" width="873" height="526" class="img_ev3q"></p>
<p>然后呢 这个 Source Domain 上的这些 Image,它的 Classification 的这个 Cross Entropy,就 Source Domain 这些 Image,它是有 Label 的,所以你可以算它们的 Cross Entropy,你根据它们的 Cross Entropy,订出一个 Loss</p>
<p>这边是有一个 L,L 是这个 Domain 的这个,这个 Source Domain 上的那些 Image,它有 Label,你可以算出 Cross Entropy,然后对於这个 Domain 的 Classifier 而言,它要去想办法分辨,Source 跟 Target Domain 的差距,它要去做一个,Binary 的 Classification 的问题,它要去做一个二元分类的问题,这个分类的问题有一个 Loss 叫做<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>那我们现在要去找一个  <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>,它可以让这个 L 越小越好</p>
<p>我们要去找一个 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>,它可以让这个<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>  越小越好</p>
<p>你说 Label Predictor 它要做的事情,就是让这个 Source Domain 的 Image,分类越正确越好,Domain Classifier 要做的事情,  就是让 Domain 的分类越正确越好</p>
<p>而 Feature Extractor 呢,Feature Extractor 它要做的事情是,它站在 Label Predictor 这边,然后呢 它要去捅 Domain Classifier 一刀,它要去做 Domain Classifier 相反的事情,所以这个 Feature Extractor,它的 Loss 是 Label Predictor 的 Loss L,去减掉 Domain Classifier 的 Loss,叫做 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>所以 Feature Extractor 它的 Loss,就是大 L 减掉<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>,你要去找一个参数 找一组参数 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>,它可以让大 L 减 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>的值越小越好</p>
<p>这个是最原始的,Domain Adversarial Training 的做法,但这真的是最好的做法吗,你可以想想看喔,那这个详情我们就不细讲,这个留给大家自己思考 自己发觉,你想想看喔,假设 Domain Classifier 它的工作,是要把 Source Domain 跟 Target Domain 分开,是要看到这种图片,它知道它的 Feature 来自 Source Domain,看到这种图片,它知道它的 Feature 来自 Target Domain,它要把这两组 Feature 分开</p>
<p>而 <strong>Feature Extractor 如果它的 Loss是 Domain Classifier 直接加一个负号</strong>,那意味著什麼,意  味著说 它要做的事情,就是跟 Domain Classifier 相反,本来 Domain Classifier 看到这张图片的 Feature,它说是 Source,那现在 Feature Extractor,是要让 Domain Classifier 看到这个图片以后,它说是 Target,看到这个图片 反过来要说是 Source,如果你这麼做,不是也把两组 Feature 分开来了吗</p>
<p>我们说我们现在要做的事情,是要让 Domain 跟,这个 Source 跟 Target Domain 没有差别,但是你今天不管是用 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>,还是负的 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>,其实都是要,把 Source 跟 Target Domain 分开呀,你去让 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 的值,本来 Domain Classifier,是要让 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 的值越小越好,你现在是负的<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>,Feature Extractor 要让 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 的值越大越好,其实也是把 Source 跟 Target Domain分开,所以这未必是最好的做法,至於怎麼做,当然这招是有用的,这招是有用的,那但是怎麼做可以做得更好,欸 这个留给大家慢慢思考</p>
<p>好 那我们来看一下,Domain Adversarial Training,最原始的 Paper,它做的结果怎麼样呢,当年看到这个 Paper 的时候,真的觉得结果非常地惊人</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911180533698-5bfb984996f066cf4778b09671607737.png" width="713" height="412" class="img_ev3q"></p>
<p>那这边呢 它做了四个任务,那上半部 是 Source Domain 的图片,这边其实都是数字辨识啦,那下半部呢 都是 Target Domain 的图片,好 如果今天呢,我们是拿 Target Domain 的图片来做 Training,Target Domain 的图片来做 Testing,那结果像是这个样子,每一个任务正确率都是 90% 以上,但如果说,我们今天是 Source Domain Training,Target Domain Testing,Train 在黑白的数字上,测试在彩色的数字上,结果直接惨掉,哇 这直接惨掉 没办法做啦, 结果直接惨掉</p>
<p>那如果加上 Domain Adversarial Training 的话,结果怎麼样呢,你会发现说本来如果只 Train 在黑白的图片上,测试在彩色的图片上,正确率 57.5</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911180619681-73aa86431475542968dad7dde212190e.png" width="882" height="182" class="img_ev3q"></p>
<p>那如果今天有做 Domain Adversarial Training,正确率就飆升到 81%,在很多其他任务上进步量都挺明显的,59 到 71,74 到 88.7,这个进步量都是挺明显的,那这个就是 Domain Adversarial Training</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="limitation">Limitation<a href="#limitation" class="hash-link" aria-label="Direct link to Limitation" title="Direct link to Limitation">​</a></h4>
<p>那刚才这整套想法,还是有一个限制,有一个小小的问题,什麼样小小的问题呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911181003396-0c8e8bae94ae97fb52d5d3014f21525e.png" width="665" height="516" class="img_ev3q"></p>
<p>我们来看看哦,今天 蓝色的圈圈跟蓝色的三角形,代表 Source Domain 上的两个 Class,那我们当然可以找一个 Boundary,去把这两组 Class 把它分开来,对於 Target Domain 上的 Data,我们没有任何的 Class 的 Label,我们就只能说所有 Target Domain 的 Data,我们都用这个正方形来表示它</p>
<p>那我们今天训练的目标,就是要让这些正方形它的分布,跟这个圈圈三角形合起来的分布越接近越好,但是什麼叫做越接近越好呢,左边这个 Case,红色的点跟蓝色的点,它们也算是蛮 Align 在一起的,也算是分布蛮接近的,右边这个 Case,红色的点跟蓝色的点,它们也算是分布蛮接近的,但是你觉得左边比较好,还是右边比较好呢,</p>
<p>没错 很多人也觉得是右边,所以我们是不是<strong>应该要让右边的状况发生</strong>,而避免让左边的状况发生呢,好 怎麼做呢,怎麼让右边的状况发生,左 边的状况不要发生呢</p>
<p>也许一个可能的想法是,我们既然知道蓝色的圈圈跟蓝色的三角形,它们的<strong>分界点</strong>在哪裡,这个分界点我们是知道的,那我们应该要让这些方形,虽然我们不知道它是哪一个类别,但我们让这些方形远离这一个分界点,怎麼让方形远离这个分界点呢,那在文献上就有很多不同的做法啦,你可以参考一下文献,看看你觉得怎麼做比较好</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="considering-decision-boundary">Considering Decision Boundary<a href="#considering-decision-boundary" class="hash-link" aria-label="Direct link to Considering Decision Boundary" title="Direct link to Considering Decision Boundary">​</a></h4>
<p>举例来说一个最简单的做法是说,呃 今天我有很多 Unlabeled 的图片,丢到 Feature Extractor,再丢到 Label Predictor 以后,我不知道它是哪一个类别,但是我希望<strong>它离 Boundary 越远越好</strong>,那什麼叫做离 Boundary 越远越好呢</p>
<ul>
<li>如果今天输出的结果非常地集中,叫做离 Boundary 远</li>
<li>如果今天输出的结果每一个类别都非常地接近,叫做离 Boundary 近</li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911181351557-efbae92f6695854d80e36fded67493c3.png" width="704" height="422" class="img_ev3q"></p>
<p>所以我希望说把 unLabled 的 Image,丢进 Feature Extractor,再丢进 Label Predictor,输出的结果,它离 Boundary 越远越好,也就是说这<strong>集中在某一个类别上</strong>,我们虽然不知道它应该算是哪一个类别,但至少应该集中在某一个类别上</p>
<p>那这只是一种招数,并不是全部,那你可以参考一下文献,比如说有一个知名的方法叫做 DIRT-T,DIRT-T,这个 DIRT-T  它其实,它 Paper 裡面还特别告诉你说,这个要唸 Dirty,要唸 Dirty,这个大家都是这个模型命名大师,都会命名一些很有创意的名字,好 这个 DIRT-T 是一个招 数,还有另外一个招数叫这个,Maximum Classifier Discrepancy,如果你要在这个 Domain Adaptation 座位裡面,得到最好的结果的话,那这些招数是不可或缺的,那实际上这些招数怎麼进行,还挺复杂,这个就留给大家自己研究</p>
<p>那这边还有一个问题,什麼样的问题呢,我们到目前為止,好像都假设说,<strong>Source Domain 跟 Target Domain,它的类别都要是一模一样</strong>,Source Domain 假设是影像分类的问题,Source Domain 有老虎 狮子跟狗,Target Domain 也应该要有老虎 狮子跟狗,但是真的一定会这样吗</p>
<p>Target Domain 是没有 Label 的,我们根本不知道 Target Domain 裡面,有什麼样的类别</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911181655614-b11735392db3b43050edf9e6085db5e1.png" width="659" height="465" class="img_ev3q"></p>
<p>而在这个图示裡面 这个实心的,实线的圈圈代表,Source Domain 裡面有的东西,这个虚实线的圈圈,代表 Target Domain 裡面有的东西,所以呢 有没有可能是,这个 <strong>Source Domain 裡面的东西比较多,Target Domain 裡面的东西比较少</strong>呢,有没有可能是,<strong>Source Domain 裡面的东西比较少,Target Domain 的东西比较多</strong>呢,有没有可能两者虽然有交集,但是各自都有独特的类别呢,这都是有可能发生的</p>
<p>所以在这个前提之下,你说 Source Domain 跟 Target Domain,你硬要把它们完全 Align 在一起,听起来有点问题呀,因為举例来说在这个 Case 裡面,哦 你说你要让 Source Domain 的 Data,跟 Target Domain 的 Data,它们的 Feature 完全 Match 在一起,那意味著说,你硬是要让老虎去变得跟狗像,或者是老虎硬是要变得跟狮子像,到时候你就分不出老虎这个类别了</p>
<p>听起来就是有问题的方法,那怎麼解决这个问题,怎麼解决 Source Domain 跟 Target Domain,它可能有不一样的 Label 的问题,那你可以参见这个,Universal Domain Adaptation   这篇文章</p>
<p>好 那我们来看看有没有同学有问题要问的,好 有同学问说</p>
<p><strong>如果 Feature Extractor 是 CNN,而不是 Linear Layer,那 Domain Classifier Input,就是 Feature Map,拉直的 Latent Embedding,这样 Latent Space 学到的东西,把两个 Domain 分部弥平会不会有影响,因為 Feature Map 本来就有 Space 的关係,现在却硬是被拉直</strong></p>
<p>答：</p>
<p>你说得非常对,真的 你说得非常对,就是 Feature Extractor,它是一个复杂的 Network,然后我们硬是要,把两个 Domain 的东西拉在一起,会不会变成它只是為了拉在一起而拉在一起,它根本就没有学到,我们本来希望,这个 Feature Space 学到的东西呢,简单的回答就是 会,会,所以 Domain Adaptation,没有大家想像得那麼容易 Train 起来,虽然好像刚才讲得都非常地顺利,那作业裡面可以自己体验一下啦,这个 Domain Adaptation,算是偏难做的一个作业,所以 呃 这一个,你知道我们在 Train 的时候,我们有两件事情,有两件事互相结抗,一个是要去骗过 Domain Classifier,另外一个是要让分类变正确,那我们期待说这两件事情都可以同时做好,也就是说一方面既骗过 Domain Classifier,一方面又分类分得好,那就同时把两个 Domain Align 在一起,同时 Latent Space,我们又希望它的分布是正确的,比如说我们觉得 1 跟 7 比较像,那他们為了要让 Classifier 做好,那今天你的 Feature Extractor,就会让 1 跟 7 比较像,然后 1 跟,比如说 1 跟 4 比较不像,它就让 1 跟 4 拉得比较远一点,我们期待说,藉由需要把 Label Predictor 的 Performance,冲高这件事情,latent representation 裡面的这个 Space,仍然是保留一个比较好的 Latent Space,但是不一定 这件事不一定总是会成功了,如果你今天你给 Domain Classifier,就是要骗过 Domain Classifier,这件事情的权重太大,你的 Model 就会学到说,它都只想骗过 Domain Classifier,它就不会產生好的 Latent Space,所以刚才同学问的问题,确实是有可能会发生的,所以大家在实做的时候,这个也是有些参数要调的,好,好 希望这样有回答到同学的问题</p>
<p>那接下来 还有一个更严峻的状况,刚才我们是假设说没有 Labeled Data,但至少有一大堆,这个时候你还可以说,我要把两个 Space 呢 把它拉在一起</p>
<p>但是有一个可能是,假设不只没有 Label,而且 Data 还很少,比如说我就只有一张而已</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911182233057-7b75168dccdec4638a4570c91ba727ba.png" width="708" height="283" class="img_ev3q"></p>
<p>这个时候你只有一张,你的这个 Target Domain 只有一张,只有一个点,你根本没有办法跟那个 Source Domain,把它 Align 在一起,这个时候怎麼办呢,假设 Target Domain 的 Data 非常少的时候,怎麼办呢,也不是没有方法啦</p>
<p>有一个方法叫做 ==Testing Time Training==,它的缩写是 TTT,这个我们就把连结附在这边给大家参考,Testing Time Training 就是想要处理,假设我的 Target Domain 没有 Lable,而且还只有一张的时候,到底应该要怎麼办</p>
<p>但其实还有一个更严峻的状况,这个状况是,如果我什麼都不知道怎麼办呢,如果我们对 Target Domain 一无所知的话,怎麼办呢</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911182329234-1353f75ea0b6d7c9bf4b93ddc3264bcd.png" width="720" height="278" class="img_ev3q"></p>
<p>这个时候又分成两种情形,对 Target Domain 一无所知的这种问题,这个时候我们就不叫 Domain 的 Adaptation,通常就叫 ==Domain Generalization==</p>
<p><img decoding="async" loading="lazy" src="/assets/images/image-20210911182517320-29ce1267da196d8532fdb78bbababbbd.png" width="718" height="528" class="img_ev3q"></p>
<p>因為我们并不是要,Adapt 到某一个特定的 Domain 上,我们对那个特定的 Domain 已经一无所知了,我们是期待今天机器学到,Domain Generalization,在 Testing 的时候,不管来什麼神奇的 Domain,它都可以处理,那 Domain Generalization,又分成两种状况</p>
<ul>
<li>
<p>一种状况是我的训练资料非常地丰富,本来就包含了各式各样不同的 Domain,假设你要做猫狗的分类器,那你现在呢 在训练资料裡面,有真实的猫跟狗的照片,有素描的猫跟狗的照片,然后有这个水彩画的猫跟狗的照片,期待因為训练资料有多个 Domain,模型可以学到如何弥平 Domain 间的差异,今天有测试资料是卡通的猫跟狗,它也可以处理,这是一种状况,那这种状况你还比较能够想像要怎麼处理,那我们这边就不细讲,我们都只各放一些有代表性的论文,给大家参考</p>
</li>
<li>
<p>但还有另外一种,你会觉得真的不知如何下手的状况是,假设训练资料只有一个 Domain 呢,假设你的训练资料只有一个 Domain,而测试资料有多种不同的 Domain 的话,怎麼处理呢,在文献上也不是没有人试,也是有人试著去解惑这种问题的,那他怎麼做呢,这细节我们就不讲啦,在概念上就是有点像是 Data Augmentation,虽然你只有一个 Domain 的资料,想个 Data Augmentation 的方法,去產生多个 Domain 的资料,然后你就可以套上面这个 Secnario 来做做看,看能不能够在测试的时候,新的 Domain 都可以做好,好 这个是 Domain Generalization</p>
</li>
</ul>
<p>那这个部分就是很简短的跟大家带过,这个 Domain Adaptation 的种种技术,更多的细节,在下一堂课助教的说明裡面</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#domain-shift" class="table-of-contents__link toc-highlight">Domain Shift</a></li><li><a href="#domain-adaptation" class="table-of-contents__link toc-highlight">Domain Adaptation</a><ul><li><a href="#basic-idea" class="table-of-contents__link toc-highlight">Basic Idea</a></li><li><a href="#domain-adversarial-training" class="table-of-contents__link toc-highlight">Domain Adversarial Training</a></li></ul></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>